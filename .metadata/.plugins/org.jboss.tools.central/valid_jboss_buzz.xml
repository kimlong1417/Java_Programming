<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Use Red Hat's single sign-on technology to secure services through Kerberos</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/28/use-red-hats-single-sign-technology-secure-services-through-kerberos" /><author><name>Rishabh Singh</name></author><id>4bd743c2-cdfd-40e9-ba42-4973b71428a4</id><updated>2022-04-28T07:00:00Z</updated><published>2022-04-28T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat's single sign-on technology&lt;/a&gt; is an identity and access management solution based on standard identity protocols (SAML, OpenID Connect) to perform authentication of users and share user information for access control. Red Hat's SSO sources user information from a &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.5/html/server_administration_guide/user-storage-federation"&gt;federated user database&lt;/a&gt;, or &lt;em&gt;user federation,&lt;/em&gt; and it provides the option to configure the &lt;a href="https://web.mit.edu/kerberos/"&gt;Kerberos protocol&lt;/a&gt; for this purpose.&lt;/p&gt; &lt;p&gt;In this article, you'll see how to set up Red Hat's SSO to authenticate users using the standard Kerberos protocol along with the &lt;a href="https://www.ietf.org/rfc/rfc2478.txt"&gt;Simple and Protected GSS_API Negotiation Mechanism&lt;/a&gt; (SPNEGO) specification.&lt;/p&gt; &lt;p&gt;To use Kerberos, Red Hat's SSO must set up an identity called a &lt;em&gt;service principal&lt;/em&gt;. The user gains access to Red Hat's SSO through Kerberos in a two-step process: first they obtain a Ticket Granting Ticket (TGT) and then they obtain service tickets (ST).&lt;/p&gt; &lt;p&gt;Objects in the Kerberos key distribution center (KDC) database are known as &lt;em&gt;principals.&lt;/em&gt; Each principal is a user, service, or host. For this example, you will add a user principal and an HTTP service principal.&lt;/p&gt; &lt;p&gt;Figure 1 illustrates the flow of information and tokens.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/arch_4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/arch_4.png?itok=G7hGU7Cg" width="781" height="588" alt="A client authenticates both with the Kerberos KDC and with Red Hat's SSO." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. A client authenticates both with the Kerberos KDC and with Red Hat's SSO. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: A client authenticates both with the Kerberos KDC and with Red Hat's SSO.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;To follow this example, you need at least two &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; servers sharing a network and a domain. The example uses &lt;code&gt;s1.example.com&lt;/code&gt; and &lt;code&gt;s2.example.com&lt;/code&gt; as the names for the systems, but you'll want to substitute in yours. Red Hat's single sign-on technology should be installed on &lt;code&gt;s2.example.com&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We've used Mozilla Firefox in the example screenshots to display the services and authenticate with Red Hat's single sign-on servers.&lt;/p&gt; &lt;h2&gt;Summary of steps in this article&lt;/h2&gt; &lt;p&gt;The procedure we'll go through breaks down as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Set up the Kerberos server &lt;ol&gt; &lt;li&gt;Configure the Kerberos server&lt;/li&gt; &lt;li&gt;Add principals and the export keytab&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;Set up Red Hat's SSO server &lt;ol&gt; &lt;li&gt;Configure the service principal and keytab file&lt;/li&gt; &lt;li&gt;Enable Kerberos processing&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;Set up your client machine &lt;ol&gt; &lt;li&gt;Configure the Kerberos client&lt;/li&gt; &lt;li&gt;Enable logins through SPNEGO&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;Authenticate to Kerberos&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Set up the Kerberos server&lt;/h2&gt; &lt;p&gt;In this section, you'll install and configure a Kerberos server. This server will be used later to create service tickets that authenticate users to Red Hat's SSO.&lt;/p&gt; &lt;p&gt;We are using EXAMPLE.COM as our Kerberos realm. The Kerberos server (KDC) will be running on the host &lt;code&gt;s1.example.com&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Configure the Kerberos server&lt;/h3&gt; &lt;p&gt;As an administrator on your system, enter the following commands.&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;Install the Kerberos server and relevant libraries on &lt;code&gt;s1.example.com&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# yum install krb5-server krb5-workstation sssd*&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Review the &lt;code&gt;/etc/krb5.conf&lt;/code&gt; and &lt;code&gt;/var/kerberos/krb5kdc/kdc.conf&lt;/code&gt; files. Configure the realms as EXAMPLE.COM, and &lt;code&gt;kdc&lt;/code&gt; and &lt;code&gt;admin_server&lt;/code&gt; as &lt;code&gt;s1.example.com&lt;/code&gt;, as follows. Here's&lt;code&gt;kdc.conf&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;[kdcdefaults] kdc_ports = 88 kdc_tcp_ports = 88 spake_preauth_kdc_challenge = edwards25519 [realms] EXAMPLE.COM = { #master_key_type = aes256-cts acl_file = /var/kerberos/krb5kdc/kadm5.acl dict_file = /usr/share/dict/words admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab supported_enctypes = aes256-cts:normal aes128-cts:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And here's &lt;code&gt;krb5.conf&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;includedir /etc/krb5.conf.d/ [logging] default = FILE:/var/log/krb5libs.log kdc = FILE:/var/log/krb5kdc.log admin_server = FILE:/var/log/kadmind.log [libdefaults] dns_lookup_realm = false ticket_lifetime = 24h renew_lifetime = 7d forwardable = true rdns = false pkinit_anchors = FILE:/etc/pki/tls/certs/ca-bundle.crt spake_preauth_groups = edwards25519 default_realm = EXAMPLE.COM default_ccache_name = KEYRING:persistent:%{uid} [realms] EXAMPLE.COM = { kdc = s1.example.com admin_server = s1.example.com } [domain_realm] .example.com = EXAMPLE.COM example.com = EXAMPLE.COM &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Put the following line in your &lt;code&gt;/var/kerberos/krb5kdc/kadm5.acl&lt;/code&gt; file, so that you can get access to the EXAMPLE.COM domain as an administrator:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;*/admin@EXAMPLE.COM *&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create the KDC database using the &lt;code&gt;kdb5_util&lt;/code&gt; utility:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# kdb5_util create -s -r EXAMPLE.COM&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Start and enable the Kerberos services:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# systemctl start krb5kdc kadmin # systemctl enable krb5kdc kadmin&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create the first principal:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# kadmin.local -q "addprinc root/admin" [root@s1 ~]# systemctl start krb5kdc kadmin [root@s1 ~]# [root@s1 ~]# kadmin.local Authenticating as principal root/admin@EXAMPLE.COM with password. kadmin.local: addprinc root/admin No policy specified for root/admin@EXAMPLE.COM; defaulting to no policy Enter password for principal "root/admin@EXAMPLE.COM": Re-enter password for principal "root/admin@EXAMPLE.COM": Principal "root/admin@EXAMPLE.COM" created. kadmin.local: addprinc rishabh No policy specified for rishabh@EXAMPLE.COM; defaulting to no policy Enter password for principal "rishabh@EXAMPLE.COM": Re-enter password for principal "rishabh@EXAMPLE.COM": Principal "rishabh@EXAMPLE.COM" created. kadmin.local: &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h3&gt;Add principals and the export keytab&lt;/h3&gt; &lt;p&gt;As mentioned earlier, a KDC principal can be a user, service, or host. For this example, you will add the user principal and HTTP service principal.&lt;/p&gt; &lt;p&gt;The user principal will be used to authenticate to and get access to the account management console on Red Hat's SSO.&lt;/p&gt; &lt;p&gt;The key of the HTTP service principal will be exported to a keytab file. Later, the HTTP service principal and exported keytab will be used to configure Kerberos-based user federation using Red Hat's SSO.&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;Add the user principal:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# kadmin.local kadmin.local: addprinc rishabh kadmin.local: quit&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add the HTTP service principal and export keytab:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;kadmin.local: addprinc -randkey HTTP/s2.example.com@EXAMPLE.COM No policy specified for HTTP/s2.example.com@EXAMPLE.COM; defaulting to no policy Principal "HTTP/s2.example.com@EXAMPLE.COM" created. kadmin.local: ktadd -norandkey -k /etc/jboss_s2_Example.keytab HTTP/s2.example.com@EXAMPLE.COM Entry for principal HTTP/s2.example.com@EXAMPLE.COM with kvno 1, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/etc/jboss_s2_Example.keytab. Entry for principal HTTP/s2.example.com@EXAMPLE.COM with kvno 1, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/etc/jboss_s2_Example.keytab. Entry for principal HTTP/s2.example.com@EXAMPLE.COM with kvno 1, encryption type arcfour-hmac added to keytab WRFILE:/etc/jboss_s2_Example.keytab. Entry for principal HTTP/s2.example.com@EXAMPLE.COM with kvno 1, encryption type camellia256-cts-cmac added to keytab WRFILE:/etc/jboss_s2_Example.keytab. Entry for principal HTTP/s2.example.com@EXAMPLE.COM with kvno 1, encryption type camellia128-cts-cmac added to keytab WRFILE:/etc/jboss_s2_Example.keytab. kadmin.local: &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Set up Red Hat's SSO server&lt;/h2&gt; &lt;p&gt;In this section, you'll configure Red Hat's SSO to use Kerberos.&lt;/p&gt; &lt;h3&gt;Configure the service principal and keytab file&lt;/h3&gt; &lt;p&gt;In your Red Hat single sign-on console, navigate to &lt;strong&gt;Red Hat SSO Admin console &gt; Realm &gt; User Federation &gt; Add provider &gt; Kerberos &lt;/strong&gt; to configure the HTTP service principal and generated keytab (&lt;code&gt;jboss_s2_Example.keytab&lt;/code&gt;) from the service principal (Figure 2). The keytab file should be present on the host where the SSO server is running. For the current walkthrough, that host is &lt;code&gt;s2.example.com&lt;/code&gt;.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/settings.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/settings.png?itok=gaqDkiEb" width="1421" height="817" alt="Configure the service principal and keytab in the Required Settings screen." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. Configure the service principal and keytab in the Required Settings screen. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Configure the service principal and keytab in the Required Settings screen.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h3&gt;Enable Kerberos processing&lt;/h3&gt; &lt;p&gt;Enable Kerberos in the &lt;strong&gt;Flow&lt;/strong&gt; tab of the &lt;strong&gt;Authentication&lt;/strong&gt; screen in the console of Red Hat's SSO (Figure 3). For our purposes, you can set the Kerberos requirement to either &lt;strong&gt;ALTERNATIVE&lt;/strong&gt; or &lt;strong&gt;REQUIRED&lt;/strong&gt;. (&lt;strong&gt;ALTERNATIVE&lt;/strong&gt; means Kerberos is optional and if the user system is not configured to work with SPNEGO and Kerberos, then Red Hat's SSO will fall back to its regular login screens. &lt;strong&gt;REQUIRED &lt;/strong&gt; does not allow the user to fall back if their system is not configured to work with SPNEGO and Kerberos.)&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/authent.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/authent.png?itok=IuWkrV6N" width="1440" height="484" alt="Kerberos is configured in the Authentication screen." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. Kerberos is configured in the Authentication screen. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Configure Kerberos in the Authentication screen.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Set up your client machine&lt;/h2&gt; &lt;p&gt;The Kerberos client should be able to connect to the KDC on &lt;code&gt;s1.example.com&lt;/code&gt; and exchange tickets. The client can procure service tickets from the KDC. A service ticket will be used to authenticate with the SSO server, making use of the Kerberos user federation created in the previous step.&lt;/p&gt; &lt;h3&gt;Configure the Kerberos client&lt;/h3&gt; &lt;p&gt;To allow users to communicate and authenticate with the Kerberos server, &lt;code&gt;krb5.conf&lt;/code&gt; must be configured on the user machine. This configuration file should point to the appropriate &lt;code&gt;kdc&lt;/code&gt; and &lt;code&gt;admin_server&lt;/code&gt;—remember, in the current example these are both &lt;code&gt;s1.example.com&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;[domain_realm]&lt;/code&gt; section provides a translation from a domain name or hostname to a Kerberos realm name. For the current example, the &lt;code&gt;.example.com&lt;/code&gt; domain maps to the EXAMPLE.COM realm.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;includedir /etc/krb5.conf.d/ [logging] default = FILE:/var/log/krb5libs.log kdc = FILE:/var/log/krb5kdc.log admin_server = FILE:/var/log/kadmind.log [libdefaults] dns_lookup_realm = false ticket_lifetime = 24h renew_lifetime = 7d forwardable = true rdns = false pkinit_anchors = FILE:/etc/pki/tls/certs/ca-bundle.crt spake_preauth_groups = edwards25519 default_realm = EXAMPLE.COM default_ccache_name = KEYRING:persistent:%{uid} [realms] EXAMPLE.COM = { kdc = s1.example.com admin_server = s1.example.com } [domain_realm] .example.com = EXAMPLE.COM example.com = EXAMPLE.COM &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Enable logins through SPNEGO&lt;/h3&gt; &lt;p&gt;Next, you need to enable SPNEGO logins in the browser. To enable them in Mozilla Firefox, allow &lt;code&gt;.example.com&lt;/code&gt; (note the presence of the initial period) in the &lt;code&gt;network.negotiate-auth.trusted-uris&lt;/code&gt; configuration option as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;In the address bar of Firefox, type &lt;strong&gt;about:config&lt;/strong&gt; to display the list of current configuration options.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;In the &lt;strong&gt;Filter&lt;/strong&gt; field, type &lt;strong&gt;&lt;code&gt;negotiate&lt;/code&gt;&lt;/strong&gt; to restrict the list of options.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Double-click the &lt;strong&gt;network.negotiate-auth.trusted-uris&lt;/strong&gt; entry.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Enter the name of the domain against which to authenticate, including the preceding period (&lt;strong&gt;.&lt;/strong&gt;). If you want to add multiple domains, enter them in a comma-separated list. The result should look like Figure 4.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig4_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig4_2.png?itok=_iy-3tEa" width="600" height="79" alt="Screenshot showing how to configure Mozilla to use Kerberos" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Configuring Mozilla to use Kerbereos. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;h2&gt;Authenticate to Red Hat's SSO account console&lt;/h2&gt; &lt;p&gt;Now that your systems are set up to use Red Hat's SSO and Kerberos, a user can initiate authentication by entering Kerberos's &lt;code&gt;kinit&lt;/code&gt; command, as in the following listing. The rest of this section lays out the sequence of events, as diagrammed in Figure 1, that the servers go through to satisfy the user's request. Figure 5 illustrates the Kerberos Authentication Service request and response.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; [rissingh@s2 configuration]$ klist klist: Credentials cache 'KCM:109626' not found [rissingh@s2 configuration]$ env KRB5_CONFIG=/home/rissingh/Desktop/Rough/Cases/RHSSO_Rough/Cases/Raw_Setup/kerberos/krb5.conf kinit rishabh Password for rishabh@EXAMPLE.COM: [rissingh@s2 configuration]$ klist Ticket cache: KCM:109626 Default principal: rishabh@EXAMPLE.COM Valid starting Expires Service principal 08/27/2021 23:23:24 08/28/2021 23:23:24 krbtgt/EXAMPLE.COM@EXAMPLE.COM renew until 08/27/2021 23:23:24 &lt;/code&gt; &lt;/pre&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig5_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig5_2.png?itok=SK1AN0Zb" width="600" height="31" alt="Screenshot" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Kerberos Authentication Service request and response.&lt;/figcaption&gt; &lt;/figure&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;The initial client request is an AS-REQ message, which asks for a TGT from the KDC. (Figure 6 and the subsequent figures are screenshots of the &lt;code&gt;tcpdump&lt;/code&gt; command offering visibility into the processing happening behind the scenes.)&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig6_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig6_2.png?itok=MRu0yOLs" width="460" height="321" alt="tcpdump screenshot" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Requesting a TGT.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The AS processes the AS-REQ and responds back with an AS-REP message that includes the TGT.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig7_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig7_2.png?itok=uQqFY6DP" width="374" height="295" alt="tcpdump screenshot" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Responding with a TGT.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The user now has access to account management on Red Hat's SSO, which, assuming you've followed the steps outlined in this article, is now a Kerberized service.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig8.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig8.png?itok=SKze1OYL" width="600" height="338" alt="Screenshot showing Kerberos authentication flow" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 8: Red Hat SSO is now a Kerberized service.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A TGS-REQ message, initiated to the Ticket Granting Service (TGS) for a service ticket, includes the TGT received in the AS-REP message earlier.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig9_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig9_0.png?itok=bTgXNOPQ" width="540" height="263" alt="tcpdump screenshot" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: A TGS-REQ message.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Ticket Granting Service responds to the TGS-REQ request with a TGS-REP message that includes the requested service ticket.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig10_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig10_0.png?itok=vg-WDtkW" width="462" height="293" alt="tcpdump screenshot" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 10: A TGS-REP message.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Red Hat's SSO responds back with an HTTP 401 message containing a &lt;code&gt;WWW-Authenticate: Negotiate&lt;/code&gt; header.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig11.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig11.png?itok=F-VLcpgm" width="600" height="338" alt="Kerbereos authentication flow screenshot" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 11: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 11: WWW-Authenticate: Negotiate header received from Red Hat's SSO.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Execute the &lt;code&gt;klist&lt;/code&gt; command to list the service ticket received for the &lt;code&gt;HTTP/s2.example.com@EXAMPLE.COM&lt;/code&gt; service principal in step 5.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; [rissingh@s2 configuration]$ klist Ticket cache: KCM:109626 Default principal: rishabh@EXAMPLE.COM Valid starting Expires Service principal 08/27/2021 23:23:24 08/28/2021 23:23:24 krbtgt/EXAMPLE.COM@EXAMPLE.COM renew until 08/27/2021 23:23:24 08/27/2021 23:24:40 08/28/2021 23:23:24 HTTP/s2.example.com@EXAMPLE.COM renew until 08/27/2021 23:23:24 [rissingh@s2 configuration]$ &lt;/code&gt; &lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If the browser has the service ticket, it then transfers the SPNEGO token to Red Hat's SSO in the &lt;code&gt;Authorization: Negotiate 'spnego-token'&lt;/code&gt; header.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig12.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig12.png?itok=7yuLU54U" width="600" height="338" alt="Screenshot of Kerbereos authentication flow" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 12: &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 12: Transfering the SPNEGO token to Red Hat's SSO.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Red Hat's SSO authenticates the user using the SPNEGO token.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;When all these steps finish, the &lt;strong&gt;Account&lt;/strong&gt; screen for Red Hat's SSO is displayed in the browser, as shown in Figures 13 and 14.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig13.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig13.png?itok=UH3GX3Hj" width="600" height="254" alt="Screenshot of an account screen of an authenticated user" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 13: Account screen of an authenticated user. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig14.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig14.png?itok=kZGDxv8n" width="600" height="288" alt="Screenshot showing user information added in Red Hat's SSO." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 14: User information added in Red Hat's SSO. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Kerberos has been a fixture of federated security for decades. Red Hat's single sign-on technology, which enables you to secure your web applications, works well with Kerberos to provide a single sign-on experience.&lt;/p&gt; &lt;p&gt;Read more about Red Hat's SSO on Red Hat Developer:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/21/add-security-quarkus-application-using-red-hats-sso"&gt;Add security to a Quarkus application using Red Hat's SSO&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible"&gt;Deploy Keycloak single sign-on with Ansible&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/28/use-red-hats-single-sign-technology-secure-services-through-kerberos" title="Use Red Hat's single sign-on technology to secure services through Kerberos"&gt;Use Red Hat's single sign-on technology to secure services through Kerberos&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Rishabh Singh</dc:creator><dc:date>2022-04-28T07:00:00Z</dc:date></entry><entry><title type="html">Getting started with ZGC Garbage collector</title><link rel="alternate" href="http://www.mastertheboss.com/java/getting-started-with-zgc-garbage-collector/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/getting-started-with-zgc-garbage-collector/</id><updated>2022-04-27T15:33:10Z</updated><content type="html">This article will discuss the Java ZGC garbage collector and how you can configure and use it to meet your needs in modern Java applications. What is the Java ZGC? The Java ZGC is a scalable low latency garbage collector that is production-ready since Java 15. The ZGC Collector is designed to minimize GC pauses, ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Create a PrivateLink Red Hat OpenShift cluster on AWS with STS</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/27/create-privatelink-red-hat-openshift-cluster-aws-sts" /><author><name>Suresh Gaikwad</name></author><id>ebc4b271-94a2-4852-bcca-4f3dbbf7c781</id><updated>2022-04-27T07:00:00Z</updated><published>2022-04-27T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://cloud.redhat.com/products/amazon-openshift"&gt;Red Hat OpenShift Service on AWS&lt;/a&gt; is a version of the &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; hosting service managed by Amazon Web Services (AWS). Although your cluster's own integrity is secure in that environment, communicating safely outside the cluster requires considerable setup. In this article, you'll learn how to connect securely through a firewall to the internet while keeping your cluster in a private workspace. We use Amazon's &lt;a href="https://aws.amazon.com/vpc/"&gt;Virtual Private Cloud &lt;/a&gt;(VPC), &lt;a href="https://wa.aws.amazon.com/wat.concept.sts.en.html"&gt;Security Token Service&lt;/a&gt; (STS), and &lt;a href="https://aws.amazon.com/transit-gateway/"&gt;AWS Transit Gateway&lt;/a&gt; to effect secure connections.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: To follow along with this article, you should be familiar with the AWS command-line interface (CLI), and have a basic understanding of AWS networking, routing, AWS permissions, transit gateways, and OpenShift, as well as &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; shell commands.&lt;/p&gt; &lt;h2&gt;Secure connections to managed cloud services&lt;/h2&gt; &lt;p&gt;There has been a recent industry-wide shift to managed services, and Red Hat has begun to see users migrate from the self-managed OpenShift Container Platform to the OpenShift Service on AWS. Such a move allows you to take advantage of a managed OpenShift cluster while focusing business resources where they are most needed.&lt;/p&gt; &lt;p&gt;During these migrations, there is often discussion among application platform, infrastructure, cloud, networking, and security teams around the specific resources created during provisioning and these would fit into any existing architectures users may have. The solution outlined in this article will help you understand how STS can help to enhance your security, and how you can manage all your outbound internet communication securely from one place without compromising VPC isolation. By consolidating your outbound traffic, you can manage outbound communications security, scaling, and configuration in one place.&lt;/p&gt; &lt;p&gt;OpenShift Service on AWS private clusters with &lt;a href="https://aws.amazon.com/privatelink/?privatelink-blogs.sort-by=item.additionalFields.createdDate&amp;privatelink-blogs.sort-order=desc"&gt;AWS PrivateLink&lt;/a&gt; are completely private. Red Hat site reliability engineering teams will make use of PrivateLink endpoints to access the cluster for management. You don't need public subnets, route tables, or an internet gateway. Typically, OpenShift Service on AWS private clusters with PrivateLink uses a transit gateway where the VPC for OpenShift Service on AWS will not have internet access. Traffic will flow from the OpenShift Service on AWS VPC to either an on-premise system or to another VPC or AWS account that provides a single controlled point of egress.&lt;/p&gt; &lt;p&gt;The scenario we'll describe in this article uses two VPCs: A private VPC in OpenShift Service on AWS and a public-facing VPC called the egress VPC. The private VPC contains only a single, private subnet, where all of the cluster resources reside. The egress VPC has a private subnet that communicates with the private VPC through the AWS Transit Gateway, and a public subnet that filters internet traffic through a standard firewall using network address translation (NAT).&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Although the example uses a single subnet in OpenShift Service on AWS for simplicity, we strongly recommend that a production cluster use multiple availability zones to minimize the potential for outages.&lt;/p&gt; &lt;p&gt;Figure 1 shows the overall architecture. Figure 2 shows how the egress VPC handles traffic to and from the internet. Over the course of this article, you'll see the commands that set up all these resources.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/arch_3.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/arch_3.png?itok=ypOG6g5k" width="1440" height="796" alt="Our architecture connects an egress VPC for public access with a private VPC." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Our architecture connects an egress VPC for public access with a private VPC. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The example architecture connects an egress VPC for public access with a private VPC.&lt;/figcaption&gt; &lt;/figure&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/egress.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/egress.png?itok=-4M7z91D" width="1440" height="819" alt="The egress VPC runs traffic to and from the Internet through a NAT gateway." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: The egress VPC runs traffic to and from the Internet through a NAT gateway. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The egress VPC runs traffic to and from the internet through a NAT gateway&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;The procedure in this article requires:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html"&gt;AWS CLI&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The OpenShift Service on AWS &lt;a href="https://github.com/openshift/rosa/releases/tag/v1.1.7"&gt;CLI&lt;/a&gt; (&lt;code&gt;rosa&lt;/code&gt;), version 1.1.7&lt;/li&gt; &lt;li&gt;The &lt;a href="https://stedolan.github.io/jq/download/"&gt;jq&lt;/a&gt; command-line JSON processor&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Before you create an OpenShift Service on AWS cluster that uses STS, you must complete the AWS prerequisites, verify that the required &lt;a href="https://docs.openshift.com/rosa/rosa_getting_started/rosa-required-aws-service-quotas.html"&gt;AWS service quotas&lt;/a&gt; are available, and set up your environment.&lt;/p&gt; &lt;p&gt;Please follow the &lt;a href="https://docs.openshift.com/rosa/rosa_getting_started/rosa-aws-prereqs.html"&gt;OpenShift Service on AWS documentation&lt;/a&gt; to set up the account prerequisites. Review the identity and access management (IAM) policies, STS version, and firewall and security group prerequisites. Then &lt;a href="https://docs.openshift.com/rosa/rosa_getting_started/rosa-config-aws-account.html"&gt;configure&lt;/a&gt; your AWS account and enable OpenShift Service on AWS.&lt;/p&gt; &lt;h2 id="prerequisites"&gt;Create your private VPC&lt;/h2&gt; &lt;ul&gt; &lt;/ul&gt; &lt;p&gt;If this is a brand new AWS account that has never had an AWS Load Balancer installed, run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws iam create-service-linked-role --aws-service-name "elasticloadbalancing.amazonaws.com"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Configure the following environment variables, submitting your own values for the &lt;code&gt;ROSA_CLUSTER_NAME&lt;/code&gt;, &lt;code&gt;VERSION&lt;/code&gt;, and &lt;code&gt;REGION&lt;/code&gt; environment variables.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ export VERSION=4.9.21 ROSA_CLUSTER_NAME=suresh-rosa AWS_DEFAULT_REGION=ap-southeast-1 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create the private VPC where the OpenShift Service on AWS cluster will be installed:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ VPC_ID_1=`aws ec2 create-vpc --cidr-block 10.1.0.0/16 | jq -r .Vpc.VpcId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add a tag for the OpenShift Service on AWS private VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $VPC_ID_1 --tags Key=Name,Value=rosa_intranet_vpc&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Create your egress VPC&lt;/h2&gt; &lt;p&gt;Create the egress VPC with the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ VPC_ID_2=`aws ec2 create-vpc --cidr-block 10.0.0.0/16 | jq -r .Vpc.VpcId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Tag the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $VPC_ID_2 --tags Key=Name,Value=egress_vpc&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Set up DNS&lt;/h2&gt; &lt;p&gt;Configure the VPCs to allow DNS hostnames for their public IP addresses:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 modify-vpc-attribute --vpc-id $VPC_ID_1 --enable-dns-hostnames $ aws ec2 modify-vpc-attribute --vpc-id $VPC_ID_2 --enable-dns-hostnames&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Create the subnets&lt;/h2&gt; &lt;p&gt;Create a private subnet in the OpenShift Service on AWS private VPC where cluster instances will be running:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ROSA_PRIVATE_SUBNET=`aws ec2 create-subnet --vpc-id $VPC_ID_1 --cidr-block 10.1.0.0/17 | jq -r .Subnet.SubnetId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Tag the private subnet in the OpenShift Service on AWS private VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $ROSA_PRIVATE_SUBNET --tags Key=Name,Value=intranet-pvt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a private subnet in the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ EGRESS_PRIVATE_SUBNET=`aws ec2 create-subnet --vpc-id $VPC_ID_2 --cidr-block 10.0.0.0/17 | jq -r .Subnet.SubnetId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Tag the private subnet in the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $EGRESS_PRIVATE_SUBNET --tags Key=Name,Value=egress-pvt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a public subnet in the egress VPC to egress the traffic to the internet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ EGRESS_PUBLIC_SUBNET=`aws ec2 create-subnet --vpc-id $VPC_ID_2 --cidr-block 10.0.128.0/17 | jq -r .Subnet.SubnetId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Tag the public subnet in the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $EGRESS_PUBLIC_SUBNET --tags Key=Name,Value=egress-public&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Create the internet gateway in the egress VPC&lt;/h2&gt; &lt;p&gt;Create the internet gateway with the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ I_GW=`aws ec2 create-internet-gateway | jq -r .internetGateway.internetGatewayId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Tag the internet gateway:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $I_GW --tags Key=Name,Value=suresh_rosa_cluster&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Attach the internet gateway to the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 attach-internet-gateway --vpc-id $VPC_ID_2 --internet-gateway-id $I_GW&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Create the NAT gateway in the egress VPC&lt;/h2&gt; &lt;p&gt;Allocate an Elastic IP address:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ EIP=`aws ec2 allocate-address --domain vpc | jq -r .AllocationId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create the NAT gateway with the following command and allocate the new Elastic IP address:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ NAT_GATEWAY=`aws ec2 create-nat-gateway --subnet-id $EGRESS_PUBLIC_SUBNET --allocation-id $EIP | jq -r .NatGateway.NatGatewayId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Tag the Elastic IP address:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $EIP --resources $NAT_GATEWAY --tags Key=Name,Value=egress_nat_public&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The new NAT gateway should now be created and associated with your VPC.&lt;/p&gt; &lt;h2&gt;Create the AWS transit gateway&lt;/h2&gt; &lt;p&gt;Create a transit gateway to attach the two VPCs as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ T_GW=`aws ec2 create-transit-gateway | jq -r .TransitGateway.TransitGatewayId` &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Tag the transit gateway:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $T_GW --tags Key=Name,Value=suresh-transit-gateway&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The transit gateway starts in the pending state and will move to an available state in a few minutes. Once the transit gateway is in the available state, create a transit gateway VPC attachment for the OpenShift Service on AWS private VPC with a private subnet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ T_GW_A_RPV=`aws ec2 create-transit-gateway-vpc-attachment --transit-gateway-id $T_GW --vpc-id $VPC_ID_1 --subnet-ids $ROSA_PRIVATE_SUBNET | jq -r .TransitGatewayVpcAttachment.TransitGatewayAttachmentId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add a tag for the transit gateway attachment for the OpenShift Service on AWS private VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $T_GW_A_RPV --tags Key=Name,Value=transit-gw-intranet-attachment&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create the transit gateway VPC attachment for the egress VPC with a private subnet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ T_GW_A_EPV=`aws ec2 create-transit-gateway-vpc-attachment --transit-gateway-id $T_GW --vpc-id $VPC_ID_2 --subnet-ids $EGRESS_PRIVATE_SUBNET | jq -r .TransitGatewayVpcAttachment.TransitGatewayAttachmentId` &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add a tag for the transit gateway attachment for the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $T_GW_A_EPV --tags Key=Name,Value=transit-gw-egress-attachment&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Egress gateway route&lt;/h2&gt; &lt;p&gt;Grab the default transit gateway's route table ID:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ T_GW_D_RT=`aws ec2 describe-transit-gateways --transit-gateway-id $T_GW | jq -r '.TransitGateways | .[] | .Options.AssociationDefaultRouteTableId'`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add a tag for the transit gateway's route table:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $T_GW_D_RT --tags Key=Name,Value=transit-gw-rt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add a static route for internet traffic to go to the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-transit-gateway-route --destination-cidr-block 0.0.0.0/0 --transit-gateway-route-table-id $T_GW_D_RT --transit-gateway-attachment-id $T_GW_A_EPV&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Grab the main route table associated with the OpenShift Service on AWS private VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ROSA_VPC_MAIN_RT=`aws ec2 describe-route-tables --filters 'Name=vpc-id,Values='$VPC_ID_1'' --query 'RouteTables[].Associations[].RouteTableId' | jq .[] | tr -d '"'`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add a tag for the OpenShift Service on AWS VPC's main route table:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-tags --resources $ROSA_VPC_MAIN_RT --tags Key=Name,Value=rosa_main_rt &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Grab the main route table associated with the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ EGRESS_VPC_MAIN_RT=`aws ec2 describe-route-tables --filters 'Name=vpc-id,Values='$VPC_ID_2'' --query 'RouteTables[].Associations[].RouteTableId' | jq .[] | tr -d '"'`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a private route table in the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ EGRESS_PRI_RT=`aws ec2 create-route-table --vpc-id $VPC_ID_2 | jq -r .RouteTable.RouteTableId`&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Associate the private subnet from the egress VPC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 associate-route-table --route-table-id $EGRESS_PRI_RT --subnet-id $EGRESS_PRIVATE_SUBNET&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;NAT gateway route&lt;/h2&gt; &lt;p&gt;Create a route in the egress private route table for all addresses to the NAT gateway:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-route --route-table-id $EGRESS_PRI_RT --destination-cidr-block 0.0.0.0/0 --gateway-id $NAT_GATEWAY &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a route in the egress VPC's main route table for all addresses going to the internet gateway:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-route --route-table-id $EGRESS_VPC_MAIN_RT --destination-cidr-block 0.0.0.0/0 --gateway-id $I_GW &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a route in the egress VPC's main route table to direct addresses in the OpenShift Service on AWS private VPC to the transit gateway:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-route --route-table-id $EGRESS_VPC_MAIN_RT --destination-cidr-block 10.1.0.0/16 --gateway-id $T_GW &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a route in the OpenShift Service on AWS private route table to direct all of its addresses to the transit gateway:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 create-route --route-table-id $ROSA_VPC_MAIN_RT --destination-cidr-block 0.0.0.0/0 --gateway-id $T_GW &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Create a cluster using Red Hat OpenShift Service on AWS&lt;/h2&gt; &lt;p&gt;Make sure that the &lt;code&gt;rosa&lt;/code&gt; binary is downloaded and available in the current working directory with executable permissions set. Then enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./rosa create account-roles --mode auto --yes&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create your cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./rosa create cluster -y --cluster-name $ROSA_CLUSTER_NAME --region $AWS_DEFAULT_REGION --version $VERSION --private-link --machine-cidr=10.1.0.0/16 --sts --subnet-ids=$ROSA_PRIVATE_SUBNET&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output of this command should look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;I: Using arn:aws:iam::XXXXX:role/ManagedOpenShift-Installer-Role for the Installer role I: Using arn:aws:iam::XXXXX:role/ManagedOpenShift-ControlPlane-Role for the ControlPlane role I: Using arn:aws:iam::XXXXX:role/ManagedOpenShift-Worker-Role for the Worker role I: Using arn:aws:iam::XXXXX:role/ManagedOpenShift-Support-Role for the Support role W: You are choosing to use AWS PrivateLink for your cluster. STS clusters can only be private if AWS PrivateLink is used. Once the cluster is created, this option cannot be changed. I: Creating cluster 'suresh-rosa' I: To view a list of clusters and their status, run 'rosa list clusters' I: Cluster 'suresh-rosa' has been created. I: Once the cluster is installed you will need to add an Identity Provider before you can login into the cluster. See 'rosa create idp --help' for more information. I: To determine when your cluster is Ready, run 'rosa describe cluster -c suresh-rosa'. I: To watch your cluster installation logs, run 'rosa logs install -c suresh-rosa --watch'. Name: suresh-rosa ID: 1qi0bhb8o7fighppuft1n6cm5e8k2p36 External ID: OpenShift Version: Channel Group: stable DNS: suresh-rosa.sv9i.p1.openshiftapps.com AWS Account: XXXXX API URL: Console URL: Region: ap-southeast-1 Multi-AZ: false Nodes: - Control plane: 3 - Infra: 2 - Compute: 2 Network: - Service CIDR: 172.30.0.0/16 - Machine CIDR: 10.0.0.0/16 - Pod CIDR: 10.128.0.0/14 - Host Prefix: /23 STS Role ARN: arn:aws:iam::XXXXX:role/ManagedOpenShift-Installer-Role Support Role ARN: arn:aws:iam::XXXXX:role/ManagedOpenShift-Support-Role Instance IAM Roles: - Control plane: arn:aws:iam::XXXXX:role/ManagedOpenShift-ControlPlane-Role - Worker: arn:aws:iam::XXXXX:role/ManagedOpenShift-Worker-Role Operator IAM Roles: - arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-machine-api-aws-cloud-credentials - arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-cloud-credential-operator-cloud-crede - arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-image-registry-installer-cloud-creden - arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-ingress-operator-cloud-credentials - arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-cluster-csi-drivers-ebs-cloud-credent State: waiting (Waiting for OIDC configuration) Private: Yes Created: Mar 01 2022 15:33:27 UTC Details Page: https://console.redhat.com/openshift/details/s/25W6HXZWTTdk35T4ERcFTRZHHIb OIDC Endpoint URL: https://XX-oidc.s3.us-east-1.amazonaws.com/1qi0bhb8o7fighppuft1n6cm5e8k2p3 I: Run the following commands to continue the cluster creation: rosa create operator-roles --cluster suresh-rosa rosa create oidc-provider --cluster suresh-rosa &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create the Operator provider:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./rosa create operator-roles --cluster $ROSA_CLUSTER_NAME --mode auto -y&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output of this command should look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;? Permissions boundary ARN (optional): ? Role creation mode: auto I: Creating roles using 'arn:aws:iam::XXXXX:user/user' I: Created role 'suresh-rosa-f0l3-openshift-cluster-csi-drivers-ebs-cloud-credent' with ARN 'arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-cluster-csi-drivers-ebs-cloud-credent' I: Created role 'suresh-rosa-f0l3-openshift-machine-api-aws-cloud-credentials' with ARN 'arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-machine-api-aws-cloud-credentials' I: Created role 'suresh-rosa-f0l3-openshift-cloud-credential-operator-cloud-crede' with ARN 'arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-cloud-credential-operator-cloud-crede' I: Created role 'suresh-rosa-f0l3-openshift-image-registry-installer-cloud-creden' with ARN 'arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-image-registry-installer-cloud-creden' I: Created role 'suresh-rosa-f0l3-openshift-ingress-operator-cloud-credentials' with ARN 'arn:aws:iam::XXXXX:role/suresh-rosa-f0l3-openshift-ingress-operator-cloud-credentials'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create the OpenID Connect (OIDC) provider:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./rosa create oidc-provider --cluster $ROSA_CLUSTER_NAME --mode auto -y&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output of this command should look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;? OIDC provider creation mode: auto I: Creating OIDC provider using 'arn:aws:iam::XXXXX:user/user' I: Created OIDC provider with ARN 'arn:aws:iam::XXXXX:oidc-provider/XX-oidc.s3.us-east-1.amazonaws.com/1qhvtf5n3n4pvnjmeqe37dj6fnsq0htm'&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Other administrative tasks&lt;/h2&gt; &lt;p&gt;Watch the installation logs:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./rosa logs install -c $ROSA_CLUSTER_NAME --watch&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create an OpenShift Service on AWS administrative user and save the login command for later use:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./rosa create admin -c $ROSA_CLUSTER_NAME&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output of this command should look like the following. Copy and save the &lt;code&gt;oc login&lt;/code&gt; command, which can be used to log in to the cluster from the CLI:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;W: It is recommended to add an identity provider to login to this cluster. See 'rosa create idp --help' for more information. I: Admin account has been added to cluster 'suresh-rosa'. I: Please securely store this generated password. If you lose this password you can delete and recreate the cluster admin user. I: To login, run the following command: oc login https://api.suresh-rosa.sv9i.p1.openshiftapps.com:6443 --username cluster-admin --password KfVVi-GgtcP-uSgYc-2c9u3 I: It may take up to a minute for the account to become active.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;List the cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./rosa list cluster&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once the cluster has finished installing, it's time to validate it. Validation when using a private link requires the use of a jump host. Create a jump host in the public subnet with the following command, replacing &lt;code&gt;&lt;ami-id&gt;&lt;/code&gt; with the exact ami-id from your environment and &lt;code&gt;rosakeypair&lt;/code&gt; with the SSH key pair details:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws ec2 run-instances --image-id &lt;ami-id&gt; --count 1 --instance-type t2.micro --key-name rosakeypair --subnet-id $EGRESS_PUBLIC_SUBNET --associate-public-ip-address&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Refer to AWS documentation for more options you can use to create the instances.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article was inspired by real-world customer experience. If you want to traverse the traffic from multiple VPCs before network packets goe outside your infrastructure from OpenShift on AWS cluster, or when network packets enter your infrastructure to communicate with OpenShift on AWS cluster, the approach taken in this article will help you to achieve your requirements. You can use the same approach to connect more than two VPCs to forward the traffic from the internal VPC to the internet. In this way, after completing the steps outlined here, your private resources can communicate with internet.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/27/create-privatelink-red-hat-openshift-cluster-aws-sts" title="Create a PrivateLink Red Hat OpenShift cluster on AWS with STS"&gt;Create a PrivateLink Red Hat OpenShift cluster on AWS with STS&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Suresh Gaikwad</dc:creator><dc:date>2022-04-27T07:00:00Z</dc:date></entry><entry><title>Monitoring Quarkus JVM Mode With Cryostat</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/monitoring-quarkus-jvm-mode-with-cryostat/&#xA;            " /><author><name>Andrew Azores</name></author><id>https://quarkus.io/blog/monitoring-quarkus-jvm-mode-with-cryostat/</id><updated>2022-04-27T00:00:00Z</updated><published>2022-04-27T00:00:00Z</published><summary type="html">Cryostat is a profiling and monitoring tool that leverages the JDK Flight Recorder (JFR) framework already present in your Java applications running on the HotSpot JVM. Cryostat provides an in-cluster collection hub for easy and secure access to your JDK Flight Recorder data from outside the cluster. Cryostat is a...</summary><dc:creator>Andrew Azores</dc:creator><dc:date>2022-04-27T00:00:00Z</dc:date></entry><entry><title type="html">RESTEasy 6.1.0.Beta2 Release</title><link rel="alternate" href="https://resteasy.github.io/2022/04/26/resteasy-6.1.0.Beta2/" /><author><name /></author><id>https://resteasy.github.io/2022/04/26/resteasy-6.1.0.Beta2/</id><updated>2022-04-26T18:11:11Z</updated><dc:creator /></entry><entry><title>Orchestrate offloaded network functions on DPUs with Red Hat OpenShift</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/26/orchestrate-offloaded-network-functions-dpus-red-hat-openshift" /><author><name>Erwan Gallen</name></author><id>bac918cf-fe82-4689-a022-2dc4156d304a</id><updated>2022-04-26T10:00:00Z</updated><published>2022-04-26T10:00:00Z</published><summary type="html">&lt;p&gt;The traditional CPU-centric system architecture is being replaced by designs where systems are aggregated from independently intelligent devices. These systems have their own compute capabilities and can natively run network functions with an accelerated data plane. The new model allows us to offload to accelerators not only the individual subroutines but whole software subsystems, such as networking or storage, with cloud-like security isolation and architectural compartmentalization.&lt;/p&gt; &lt;p&gt;One of the most prominent examples of this new architecture is the data processing unit (DPU). DPUs offer a complete compute system with an independent software stack, network identity, and provisioning capabilities. The DPU can host its own applications using either embedded or orchestrated deployment models.&lt;/p&gt; &lt;p&gt;The unique capabilities of the DPU allow for key infrastructure functions and their associated software stacks to be completely removed from the host node’s CPU cores and to be relocated onto the DPU. For instance, DPU could host the management plane of the network functions and part of the control plane, while the data plane could be accelerated by dedicated Arm cores, ASICs, GPUs, or FPGA IPs. Because DPUs can run independent software stacks locally, multiple network functions could run simultaneously on the same devices with service chaining and shared accelerators to provide generic in-line processing.&lt;/p&gt; &lt;h2&gt;OVN/OVS offloading on NVIDIA BlueField-2 DPUs&lt;/h2&gt; &lt;p&gt;Red Hat has collaborated with NVIDIA to extend the operational simplicity and hybrid cloud architecture of &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; to NVIDIA Bluefield-2 DPUs. Red Hat OpenShift 4.10 provides BlueField-2 OVN/OVS offload as a developer preview.&lt;/p&gt; &lt;p&gt;Installing OpenShift Container Platform on a DPU makes it possible to offload packet processing from the host CPUs to the DPU. Offloading resource-intensive tasks like packet processing from the server’s CPU to the DPU can free up cycles on the OpenShift worker nodes to run more user applications. OpenShift brings portability, scalability, and orchestration to DPU workloads, giving you the ability to use standard &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; APIs along with consistent system management interfaces for both the host systems and DPUs.  &lt;/p&gt; &lt;p&gt;In short, utilizing OpenShift with DPUs lets you get the benefits of DPUs without sacrificing the hybrid cloud experience or adding unnecessary complexity to managing IT infrastructure.&lt;/p&gt; &lt;p&gt;To manage DPUs, Red Hat OpenShift replaces the native BlueField operating system (OS) on each DPU and is deployed using a two-cluster design that consists of:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;Tenant cluster running on the host servers (x86)&lt;/li&gt; &lt;li aria-level="1"&gt;Infrastructure cluster running on DPUs (Arm)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The architecture is illustrated in Figure 1.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image5_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image5_0.png?itok=jfJF-JJg" width="600" height="262" alt="Diagram of the architecture." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The two-cluster design.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;In this architecture, DPUs are provisioned as worker nodes of the Arm-based OpenShift infrastructure cluster. This is the blue cluster in Figure 1. The tenant OpenShift cluster, composed of the x86 servers, is where user applications typically run. This is the green cluster. In this deployment, each physical server runs both a tenant node on the x86 cores and an infrastructure node on the DPU Arm cores.&lt;/p&gt; &lt;p&gt;This architecture allows you to minimize the attack surface by decoupling the workload from the management cluster.&lt;/p&gt; &lt;p&gt;This architecture also streamlines operations by decoupling the application workload from the underlying infrastructure. That allows IT Ops to deploy and maintain the platform software and accelerated infrastructure while DevOps deploys and maintains application workloads independently from the infrastructure layer.&lt;/p&gt; &lt;p&gt;Red Hat OpenShift 4.10 provides capabilities for offloading Open Virtual Network (&lt;a href="https://www.ovn.org/en/"&gt;&lt;u&gt;OVN&lt;/u&gt;&lt;/a&gt;) and Open Virtual Switch (&lt;a href="https://www.openvswitch.org/"&gt;&lt;u&gt;OVS&lt;/u&gt;&lt;/a&gt;) services that typically run on servers, from the host CPU to the DPU. We are offering this functionality as a developer preview and enabling the following components to support OVN/OVS hardware offload to NVIDIA BlueField-2 DPUs:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;DPU Network Operator: This component is used with the infrastructure cluster to facilitate OVN deployment.&lt;/li&gt; &lt;li aria-level="1"&gt;DPU mode for OVN Kubernetes: This component is assigned by the cluster network operator for the tenant cluster.&lt;/li&gt; &lt;li aria-level="1"&gt;SR-IOV network operator: This component discovers compatible network devices, such as the ConnectX-6 Dx NIC embedded inside the BlueField-2 DPU, and provisions them for SR-IOV access by pods on that server&lt;/li&gt; &lt;li aria-level="1"&gt;ConnectX NIC Fast Data Path on Arm&lt;/li&gt; &lt;li aria-level="1"&gt;Kernel flow offloading (TC Flower)&lt;/li&gt; &lt;li aria-level="1"&gt;Experimental use of OpenShift Assisted Installer and BlueField-2 BMC&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The combination of these components allows us to move ovn-kube-node services from the x86 host to the BlueField-2 DPU.&lt;/p&gt; &lt;p&gt;The network flows are offloaded in this manner (see Figure 2):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The ovn-k8s components are moved from the x86 host to the DPU (ovn-kube, vswitchd, ovsdb).&lt;/li&gt; &lt;li&gt;The Open vSwitch data path is offloaded from the BlueField Arm CPU to the ConnectX-6 Dx ASIC.&lt;/li&gt; &lt;/ul&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image4_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image4_1.png?itok=Vq8xo5CJ" width="600" height="450" alt="Diagram of the network flows." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Illustrating the network flows.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;The following Open vSwitch datapath flows managed by ovn-k8s are offloaded to a BlueField-2 DPU that is running OpenShift 4.10:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Pod to pod (east-west)&lt;/li&gt; &lt;li&gt;Pod to clusterIP service backed by a regular pod in diff node (east-west)&lt;/li&gt; &lt;li&gt;Pod to external (north-south)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let’s take a more detailed look at the testbed setup.&lt;/p&gt; &lt;h2&gt;Install and configure an accelerated infrastructure with OpenShift and NVIDIA Bluefield-2 DPUs&lt;/h2&gt; &lt;p&gt;In our sample testbed shown in Figure 3, we are using two x86 hosts with BlueField-2 DPU PCIe cards installed. Each DPU has eight Arm cores, two 25GB network ports, and a 1GbE management port. We’ve wired 25GB ports to a switch and also connected the BMC port of the DPU to a separate network to manage the device with IPMI.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image2.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image2.jpg?itok=imhaEiEG" width="600" height="450" alt="A photo of the sample testbed." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: The sample testbed.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Next, we’ve installed Red Hat OpenShift Container Platform 4.10 on a DPU to offload packet processing from the host x86 to the DPU. Offloading resource-intensive computational tasks such as packet processing from the server’s CPU to the DPU frees up cycles on the OpenShift Container Platform worker nodes to run more applications or to run the same number of applications more quickly.&lt;/p&gt; &lt;h3&gt;OpenShift and DPU deployment architecture&lt;/h3&gt; &lt;p&gt;In our setup, OpenShift replaces the native Bluefield OS. We used the two-cluster architecture where DPU cards are provisioned as worker nodes in the Arm-based infrastructure cluster. The tenant cluster composed of x86 servers was used to run user applications.&lt;/p&gt; &lt;p&gt;We followed these steps to deploy tenant and infrastructure clusters:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Install &lt;a href="https://cloud.redhat.com/blog/using-the-openshift-assisted-installer-service-to-deploy-an-openshift-cluster-on-metal-and-vsphere"&gt;&lt;u&gt;OpenShift assisted installer&lt;/u&gt;&lt;/a&gt; on the installer node using Podman.&lt;/li&gt; &lt;li&gt;Install the infrastructure cluster.&lt;/li&gt; &lt;li&gt;Install the tenant cluster.&lt;/li&gt; &lt;li&gt;Install the DPU Network Operator on the infrastructure cluster.&lt;/li&gt; &lt;li&gt;Configuring SR-IOV Operator for DPUs.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;For details about how to install the OpenShift 4.10 on BlueField with OVN/OVS hardware offload, refer to the &lt;a href="https://access.redhat.com/articles/6804281"&gt;documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;When the cluster is deployed on the BlueField, the OVN configuration is automated with the "DPU Network Operator"; this operator can be installed in the OpenShift console or with the &lt;code&gt;oc&lt;/code&gt; command.&lt;/p&gt; &lt;p&gt;As shown in Figure 4, the DPU operator is available for the Arm-based OpenShift clusters in the catalog and not visible in x86 OpenShift clusters.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image1_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image1_2.png?itok=zQH1Dn_1" width="600" height="509" alt="The DPU Network Operator shown in the Operator Hub catalog." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: The DPU Network Operator shown in the OperatorHub catalog.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Validate installation using the OpenShift console&lt;/h2&gt; &lt;p&gt;When you have completed the last step, you have two OpenShift clusters running. We will make some console checks to show the configuration done and benchmark the OVS/OVN offloading.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tenant cluster:&lt;/strong&gt; We can list the nodes of the Tenant cluster nodes:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-tenant ~]$ oc get nodes NAME STATUS ROLES AGE VERSION tenant-master-0 Ready master 47d v1.23.3+759c22b tenant-master-1 Ready master 47d v1.23.3+759c22b tenant-master-2 Ready master 47d v1.23.3+759c22b tenant-worker-0 Ready worker 47d v1.23.3+759c22b tenant-worker-1 Ready worker 47d v1.23.3+759c22b x86-worker-advnetlab13 Ready dpu-host,worker 35d v1.23.3+759c22b x86-worker-advnetlab14 Ready dpu-host,worker 41d v1.23.3+759c22b&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Infrastructure cluster:&lt;/strong&gt; We can list the nodes of the Infrastructure cluster, including the BlueField-2 nodes with the machine-config pool name &lt;code&gt;dpu-worker&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-infrastructure ~]$ oc get nodes NAME STATUS ROLES AGE VERSION bf-13 Ready dpu-worker,worker 71d v1.22.1+6859754 bf-14 Ready dpu-worker,worker 74d v1.22.1+6859754 master-0 Ready master 75d v1.22.1+6859754 master-1 Ready master 75d v1.22.1+6859754 master-2 Ready master 75d v1.22.1+6859754 worker-0 Ready worker 70d v1.22.1+6859754 worker-1 Ready worker 70d v1.22.1+6859754&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Tenant cluster:&lt;/strong&gt; We can list the pods running in the &lt;code&gt;openshift-ovn-kubernetes&lt;/code&gt; namespace in the tenant cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-tenant ~]$ oc get pods -n openshift-ovn-kubernetes NAME READY STATUS RESTARTS AGE ovnkube-master-99x8j 4/6 Running 7 25d ovnkube-master-qdfvv 6/6 Running 14 (15d ago) 25d ovnkube-master-w28mh 6/6 Running 7 (15d ago) 25d ovnkube-node-5xlxr 5/5 Running 5 34d ovnkube-node-6nkm5 5/5 Running 5 34d ovnkube-node-dpu-host-45crl 3/3 Running 50 34d ovnkube-node-dpu-host-r8tlj 3/3 Running 30 28d ovnkube-node-f2x2q 5/5 Running 0 34d ovnkube-node-j6w6t 5/5 Running 5 34d ovnkube-node-qtc6f 5/5 Running 0 34d [egallen@bastion-tenant ~]$ oc get pods -n openshift-ovn-kubernetes -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES ovnkube-master-99x8j 4/6 Running 7 25d 192.168.111.122 tenant-master-2 &lt;none&gt; &lt;none&gt; ovnkube-master-qdfvv 6/6 Running 14 (15d ago) 25d 192.168.111.121 tenant-master-1 &lt;none&gt; &lt;none&gt; ovnkube-master-w28mh 6/6 Running 7 (15d ago) 25d 192.168.111.120 tenant-master-0 &lt;none&gt; &lt;none&gt; ovnkube-node-5xlxr 5/5 Running 5 34d 192.168.111.121 tenant-master-1 &lt;none&gt; &lt;none&gt; ovnkube-node-6nkm5 5/5 Running 5 34d 192.168.111.122 tenant-master-2 &lt;none&gt; &lt;none&gt; ovnkube-node-dpu-host-45crl 3/3 Running 50 34d 192.168.111.113 x86-worker-advnetlab13 &lt;none&gt; &lt;none&gt; ovnkube-node-dpu-host-r8tlj 3/3 Running 30 28d 192.168.111.114 x86-worker-advnetlab14 &lt;none&gt; &lt;none&gt; ovnkube-node-f2x2q 5/5 Running 0 34d 192.168.111.123 tenant-worker-0 &lt;none&gt; &lt;none&gt; ovnkube-node-j6w6t 5/5 Running 5 34d 192.168.111.120 tenant-master-0 &lt;none&gt; &lt;none&gt; ovnkube-node-qtc6f 5/5 Running 0 34d 192.168.111.124 tenant-worker-1 &lt;none&gt; &lt;none&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Infrastructure cluster: &lt;/strong&gt;The DaemonSet and the nodes have the same &lt;code&gt;dpu-worker&lt;/code&gt; label. The ovnkube-node host network pods will be scheduled on the BlueField-2:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-infrastructure ~]$ oc get ds -n default --show-labels NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE LABELS ovnkube-node 2 2 2 2 2 beta.kubernetes.io/os=linux,node-role.kubernetes.io/dpu-worker= 65d &lt;none&gt; [egallen@bastion-infrastructure ~]$ oc get nodes --show-labels | grep dpu-worker bf-13 Ready dpu-worker,worker 71d v1.22.1+6859754 beta.kubernetes.io/arch=arm64,beta.kubernetes.io/os=linux,kubernetes.io/arch=arm64,kubernetes.io/hostname=bf-13,kubernetes.io/os=linux,network.operator.openshift.io/dpu=,node-role.kubernetes.io/dpu-worker=,node-role.kubernetes.io/worker=,node.openshift.io/os_id=rhcos bf-14 Ready dpu-worker,worker 74d v1.22.1+6859754 beta.kubernetes.io/arch=arm64,beta.kubernetes.io/os=linux,kubernetes.io/arch=arm64,kubernetes.io/hostname=bf-14,kubernetes.io/os=linux,network.operator.openshift.io/dpu=,node-role.kubernetes.io/dpu-worker=,node-role.kubernetes.io/worker=,node.openshift.io/os_id=rhcos&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Infrastructure cluster: &lt;/strong&gt;We see the ovnkube-node DaemonSet running on the two BlueField-2 infrastructure cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-infrastructure ~]$ oc get pods -n default NAME READY STATUS RESTARTS AGE ovnkube-node-hshxs 2/2 Running 13 (6d13h ago) 25d ovnkube-node-mng24 2/2 Running 17 (42h ago) 25d [egallen@bastion-infrastructure ~]$ oc get pods -n default -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES ovnkube-node-hshxs 2/2 Running 13 (6d13h ago) 25d 192.168.111.28 bf-14 &lt;none&gt; &lt;none&gt; ovnkube-node-mng24 2/2 Running 17 (42h ago) 25d 192.168.111.29 bf-13 &lt;none&gt; &lt;none&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Infrastructure cluster:&lt;/strong&gt; We get the IP address of the BlueField bf-14 to &lt;code&gt;ssh&lt;/code&gt; on it (&lt;code&gt;192.168.111.28&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-infrastructure ~]$ oc get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME bf-13 Ready dpu-worker,worker 71d v1.22.1+6859754 192.168.111.29 &lt;none&gt; Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 (Ootpa) 4.18.0-305.40.1.el8_4.test.aarch64 cri-o://1.23.0-98.rhaos4.10.git9b7f5ae.el8 bf-14 Ready dpu-worker,worker 74d v1.22.1+6859754 192.168.111.28 &lt;none&gt; Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 (Ootpa) 4.18.0-305.40.1.el8_4.test.aarch64 cri-o://1.23.0-98.rhaos4.10.git9b7f5ae.el8 master-0 Ready master 75d v1.22.1+6859754 192.168.111.20 &lt;none&gt; Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 (Ootpa) 4.18.0-305.30.1.el8_4.aarch64 cri-o://1.23.0-98.rhaos4.10.git9b7f5ae.el8 master-1 Ready master 75d v1.22.1+6859754 192.168.111.21 &lt;none&gt; Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 (Ootpa) 4.18.0-305.30.1.el8_4.aarch64 cri-o://1.23.0-98.rhaos4.10.git9b7f5ae.el8 master-2 Ready master 75d v1.22.1+6859754 192.168.111.22 &lt;none&gt; Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 (Ootpa) 4.18.0-305.30.1.el8_4.aarch64 cri-o://1.23.0-98.rhaos4.10.git9b7f5ae.el8 worker-0 Ready worker 70d v1.22.1+6859754 192.168.111.23 &lt;none&gt; Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 (Ootpa) 4.18.0-305.30.1.el8_4.aarch64 cri-o://1.23.0-98.rhaos4.10.git9b7f5ae.el8 worker-1 Ready worker 70d v1.22.1+6859754 192.168.111.24 &lt;none&gt; Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 (Ootpa) 4.18.0-305.30.1.el8_4.aarch64 cri-o://1.23.0-98.rhaos4.10.git9b7f5ae.el8&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Infrastructure cluster:&lt;/strong&gt; We can &lt;code&gt;ssh&lt;/code&gt; to one BlueField-2 of the cluster to check the configuration:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-infrastructure ~]$ ssh core@192.168.111.28 Red Hat Enterprise Linux CoreOS 410.84.202201071203-0 Part of OpenShift 4.10, RHCOS is a Kubernetes native operating system managed by the Machine Config Operator (`clusteroperator/machine-config`). WARNING: Direct SSH access to machines is not recommended; instead, make configuration changes via `machineconfig` objects: https://docs.openshift.com/container-platform/4.10/architecture/architecture-rhcos.html --- Last login: Wed Mar 30 07:50:50 2022 from 192.168.111.1 [core@bf-14 ~]$ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;On one BlueField: &lt;/strong&gt;We are running OpenShift 4.10 on the Arm cores:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[core@bf-14 ~]$ cat /etc/redhat-release Red Hat Enterprise Linux CoreOS release 4.10 [core@bf-14 ~]$ uname -m aarch64 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;On one BlueField: &lt;/strong&gt;The BlueField-2 has 8 x Armv8 A72 cores (64-bit):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[core@bf-13 ~]$ lscpu Architecture: aarch64 Byte Order: Little Endian CPU(s): 8 On-line CPU(s) list: 0-7 Thread(s) per core: 1 Core(s) per socket: 8 Socket(s): 1 NUMA node(s): 1 Vendor ID: ARM Model: 0 Model name: Cortex-A72 Stepping: r1p0 BogoMIPS: 400.00 L1d cache: 32K L1i cache: 48K L2 cache: 1024K L3 cache: 6144K NUMA node0 CPU(s): 0-7 Flags: fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;On one BlueField: &lt;/strong&gt;&lt;code&gt;dmidecode&lt;/code&gt; is a tool for dumping a computer's DMI (also called SMBIOS). The tool is exporting a table of contents. Running on the Jetson gives you an error: “No SMBIOS nor DMI entry point found, sorry.” The command is working on Bluefield-2; you can get SMBIOS data from sysfs:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[core@bf-14 ~]$ sudo dmidecode | grep -A12 "BIOS Information" BIOS Information Vendor: https://www.mellanox.com Version: BlueField:3.7.0-20-g98daf29 Release Date: Jun 26 2021 ROM Size: 4 MB Characteristics: PCI is supported BIOS is upgradeable Selectable boot is supported Serial services are supported (int 14h) ACPI is supported UEFI is supported BIOS Revision: 3.0 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;On one BlueField: &lt;/strong&gt;We can get the SOC type with the &lt;code&gt;lshw&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[core@bf-14 ~]$ lshw -C system bf-14 description: Computer product: BlueField SoC (Unspecified System SKU) vendor: https://www.mellanox.com version: 1.0.0 serial: Unspecified System Serial Number width: 64 bits capabilities: smbios-3.1.1 dmi-3.1.1 smp configuration: boot=normal family=BlueField sku=Unspecified System SKU uuid=888eecb3-cb1e-40c0-a925-562a7c62ed92 *-pnp00:00 product: PnP device PNP0c02 physical id: 1 capabilities: pnp configuration: driver=system &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;On one BlueField: &lt;/strong&gt;We have 16GB of RAM on this BlueField-2:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[core@bf-14 ~]$ free -h total used free shared buff/cache available Mem: 15Gi 2.3Gi 6.9Gi 193Mi 6.7Gi 10Gi Swap: 0B 0B 0B &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Infrastructure cluster:&lt;/strong&gt; I can get the OpenShift console URL (Figure 5) with an oc command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[egallen@bastion-infrastructure ~]$ oc whoami --show-console https://console-openshift-console.apps.bf2cluster.dev.metalkube.org [egallen@bastion-infrastructure ~]$ host console-openshift-console.apps.bf2cluster.dev.metalkube.org console-openshift-console.apps.bf2cluster.dev.metalkube.org has address 192.168.111.4 &lt;/code&gt;&lt;/pre&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image3_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image3_2.png?itok=8NZA_hBy" width="600" height="255" alt="Nodes in the OpenShift console." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Getting information about nodes in the cluster.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;&lt;strong&gt;Tenant cluster: &lt;/strong&gt;In the &lt;code&gt;testpod1&lt;/code&gt; we are running the &lt;code&gt;iperf&lt;/code&gt; server:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[root@testpod-1 /]# taskset -c 6 iperf3 -s ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- Accepted connection from 10.130.4.132, port 59326 [ 5] local 10.129.5.163 port 5201 connected to 10.130.4.132 port 59328 [ ID] Interval Transfer Bitrate [ 5] 0.00-1.00 sec 2.35 GBytes 20.2 Gbits/sec [ 5] 1.00-2.00 sec 2.46 GBytes 21.2 Gbits/sec [ 5] 2.00-3.00 sec 2.42 GBytes 20.8 Gbits/sec [ 5] 3.00-4.00 sec 2.24 GBytes 19.2 Gbits/sec [ 5] 4.00-5.00 sec 2.39 GBytes 20.5 Gbits/sec [ 5] 5.00-5.00 sec 384 KBytes 21.2 Gbits/sec - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate [ 5] 0.00-5.00 sec 11.9 GBytes 20.4 Gbits/sec receiver ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Tenant cluster: &lt;/strong&gt;In the &lt;code&gt;testpod2&lt;/code&gt;, we can get 20-21.2Gbps of throughput with TC Flower OVS hardware offloading instead of 3Gbps of traffic throughput without offloading:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[root@testpod-2 /]# taskset -c 6 iperf3 -c 10.129.5.163 -t 5 Connecting to host 10.129.5.163, port 5201 [ 5] local 10.130.4.132 port 59328 connected to 10.129.5.163 port 5201 [ ID] Interval Transfer Bitrate Retr Cwnd [ 5] 0.00-1.00 sec 2.35 GBytes 20.2 Gbits/sec 17 1.14 MBytes [ 5] 1.00-2.00 sec 2.46 GBytes 21.2 Gbits/sec 0 1.41 MBytes [ 5] 2.00-3.00 sec 2.42 GBytes 20.8 Gbits/sec 637 1.01 MBytes [ 5] 3.00-4.00 sec 2.24 GBytes 19.2 Gbits/sec 0 1.80 MBytes [ 5] 4.00-5.00 sec 2.39 GBytes 20.6 Gbits/sec 2 1.80 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 5] 0.00-5.00 sec 11.9 GBytes 20.4 Gbits/sec 656 sender [ 5] 0.00-5.00 sec 11.9 GBytes 20.4 Gbits/sec receiver iperf Done. &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This example demonstrates the benefits of composable compute architectures that include hardware-level security isolation and capabilities to offload the entire subsystem, such as networking, to the DPU hardware. This enables clean architectural compartmentalization along the same boundaries as the corresponding software services, as well as freeing up working node x83 cores so they can run more applications.&lt;/p&gt; &lt;p&gt;Unlike SmartNICs that have been niche products with proprietary software stacks, DPUs running &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt;, Kubernetes, and open source software stacks offer network function portability. And with Red Hat OpenShift, we are offering long-term support for this stack.&lt;/p&gt; &lt;p&gt;As DPUs gain more compute power, additional capabilities, and increased popularity in datacenters around the world, Red Hat and NVIDIA plan to continue work on enabling the offloading of additional software functions to DPUs.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/26/orchestrate-offloaded-network-functions-dpus-red-hat-openshift" title="Orchestrate offloaded network functions on DPUs with Red Hat OpenShift"&gt;Orchestrate offloaded network functions on DPUs with Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Erwan Gallen</dc:creator><dc:date>2022-04-26T10:00:00Z</dc:date></entry><entry><title>Red Hat Developer roundup: Best of April 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/26/red-hat-developer-roundup-best-april-2022" /><author><name>Red Hat Developer Editorial Team</name></author><id>8264f386-94d5-4766-9207-39e82b323299</id><updated>2022-04-26T07:00:00Z</updated><published>2022-04-26T07:00:00Z</published><summary type="html">&lt;p&gt;Welcome to our monthly recap of the articles we published in April! We had some important product and event announcements this month that deserve your attention:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/18/announcement-red-hat-codeready-studio-reaches-end-life"&gt;Red Hat CodeReady Studio reached its end of life&lt;/a&gt;;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/01/codeready-workspaces-scales-now-red-hat-openshift-dev-spaces"&gt;CodeReady Workspaces has scaled up and, is now Red Hat OpenShift Dev Spaces&lt;/a&gt;;&lt;/li&gt; &lt;li&gt;Red Hat Summit 2022 is fast approaching—find out which sessions are &lt;a href="https://developers.redhat.com/articles/2022/04/11/red-hat-summit-2022-developer-preview"&gt;of most interest to developers&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;And of course, we rolled out a panoply of articles to help you write code on the platforms you trust. Here are the April highlights.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: See the end of this article for the full lineup published in April 2022.&lt;/p&gt; &lt;h2&gt;What's new in GCC 12?&lt;/h2&gt; &lt;p&gt;The upcoming release of version 12 of the GCC &lt;a href="https://developers.redhat.com/products/gcc-clang-llvm-go-rust/overview"&gt;compiler&lt;/a&gt; is naturally causing quite a stir for &lt;a href="https://developers.redhat.com/topics/c"&gt;C&lt;/a&gt; developers working on &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; and other platforms. In one of our most popular articles this month, David Malcolm breaks down the &lt;a href="https://developers.redhat.com/articles/2022/04/12/state-static-analysis-gcc-12-compiler"&gt;state of static code analysis in GCC 12&lt;/a&gt;. C++ specifically is getting more support in this version of the compiler, and Marek Polacek &lt;a href="https://developers.redhat.com/articles/2022/04/11/new-c-features-gcc-12"&gt;outlines the new features&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Meanwhile, C++ is advancing on other fronts, with updates to the core standard. Jason Merrill &lt;a href="https://developers.redhat.com/articles/2022/03/29/c-standardization-core-language-progress-2021"&gt;has the highlights&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Keep secure with SSO&lt;/h2&gt; &lt;p&gt;Did you know that Red Hat makes single sign-on available in many of its products and platforms? The technology is a productized and supported version of the open source Keycloak tool. This month we offered a couple of different ways to help you get started: Romain Pelisse taught you how to &lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible"&gt;deploy Keycloak SSO with Ansible&lt;/a&gt;, while Olivier Rivat explained how to &lt;a href="https://developers.redhat.com/articles/2022/04/21/add-security-quarkus-application-using-red-hats-sso"&gt;add security to a Quarkus application using Red Hat's SSO&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Get to know Node.js&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/nodejs/all"&gt;Node.js&lt;/a&gt; makes it simple to run &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; on servers and everywhere else. Developers at IBM, Red Hat, and elsewhere are working together to create a &lt;a href="https://nodeshift.dev/nodejs-reference-architecture/"&gt;Node.js reference architecture&lt;/a&gt;; in the latest installment in &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;our series on the topic&lt;/a&gt;, Dominic Harries explains what this architecture's &lt;a href="https://developers.redhat.com/articles/2022/04/11/introduction-nodejs-reference-architecture-part-8-typescript"&gt;recommendations are for TypeScript&lt;/a&gt;. And if you're ready to get your hands dirty with some real-world development, find out how to &lt;a href="https://developers.redhat.com/articles/2022/04/21/bind-kafka-cluster-nodejs-application-easy-way"&gt;bind a Kafka cluster to a Node.js application the easy way&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Java, containerized&lt;/h2&gt; &lt;p&gt;Java might have been born in an era of big servers and traditional middleware, but it's moving forward into an era of &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized&lt;/a&gt; applications at a rapid clip. This month, Red Hat Developer delivered a pair of articles that dug deep into how Java operates in a containerized environment. Ben Evans outlined some &lt;a href="https://developers.redhat.com/articles/2022/04/19/best-practices-java-single-core-containers"&gt;best practices for Java in single-core containers&lt;/a&gt;, whereas Severin Gehwolf explained &lt;a href="https://developers.redhat.com/articles/2022/04/19/java-17-whats-new-openjdks-container-awareness"&gt;what’s new in OpenJDK's container awareness for Java 17&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Want to move beyond theory to practice? Get started with &lt;a href="https://developers.redhat.com/articles/2022/04/05/developers-guide-using-kafka-java-part-1"&gt;a developer's guide to using Kafka with Java&lt;/a&gt;, since Kafka is often used along with Kubernetes. Then dig deeper by &lt;a href="https://developers.redhat.com/articles/2022/04/13/deploy-java-application-red-hat-openshift-using-jkube"&gt;deploying a Java application on Red Hat OpenShift using JKube&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2022/04/04/writing-kubernetes-operators-java-josdk-part-3-implementing-controller"&gt;writing Kubernetes Operators in Java with JOSDK&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;April 2022 on Red Hat Developer&lt;/h2&gt; &lt;p&gt;Here's the full lineup of articles published on Red Hat Developer so far this month:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/28/build-your-first-java-serverless-function-using-quarkus-quick-start"&gt;Build your first Java serverless function using a Quarkus quick start&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/29/c-standardization-core-language-progress-2021"&gt;C++ standardization (core language) progress in 2021&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/29/develop-basic-rate-limiter-quarkus-and-redis"&gt;Develop a basic rate limiter with Quarkus and Redis&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/30/generate-and-save-html-report-jenkins-openshift-4"&gt;Generate and save an HTML report in Jenkins on OpenShift 4&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/01/codeready-workspaces-scales-now-red-hat-openshift-dev-spaces"&gt;CodeReady Workspaces scales up, is now Red Hat OpenShift Dev Spaces&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/04/writing-kubernetes-operators-java-josdk-part-3-implementing-controller"&gt;Writing Kubernetes Operators in Java with JOSDK, Part 3: Implementing a controller&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/05/automate-cicd-pull-requests-argo-cd-applicationsets"&gt;Automate CI/CD on pull requests with Argo CD ApplicationSets&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/05/developers-guide-using-kafka-java-part-1"&gt;A developer's guide to using Kafka with Java, Part 1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/06/configure-codeready-containers-aiml-development"&gt;Configure CodeReady Containers for AI/ML development&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/06/introduction-linux-bridging-commands-and-features"&gt;An introduction to Linux bridging commands and features&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/07/3-ways-install-database-helm-charts"&gt;3 ways to install a database with Helm charts&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/07/kafka-monthly-digest-march-2022"&gt;Kafka Monthly Digest: March 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/11/introduction-nodejs-reference-architecture-part-8-typescript"&gt;Introduction to the Node.js reference architecture, Part 8: TypeScript&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/11/red-hat-summit-2022-developer-preview"&gt;Red Hat Summit 2022: A developer preview&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/12/observability-2022-why-it-matters-and-how-opentelemetry-can-help"&gt;Observability in 2022: Why it matters and how OpenTelemetry can help&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/12/state-static-analysis-gcc-12-compiler"&gt;The state of static analysis in the GCC 12 compiler&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/13/deploy-java-application-red-hat-openshift-using-jkube"&gt;Deploy a Java application on Red Hat OpenShift using JKube&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/13/manage-namespaces-multitenant-clusters-argo-cd-kustomize-and-helm"&gt;Manage namespaces in multitenant clusters with Argo CD, Kustomize, and Helm&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/14/building-quarkus-applications-apache-cassandra-workshop-recap"&gt;Building Quarkus applications with Apache Cassandra: Workshop recap&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/14/generate-helm-charts-your-java-application-using-jkube-part-1"&gt;Generate Helm charts for your Java application using JKube, Part 1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/18/announcement-red-hat-codeready-studio-reaches-end-life"&gt;Announcement: Red Hat CodeReady Studio reaches end of life&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/19/best-practices-java-single-core-containers"&gt;Best practices for Java in single-core containers&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/19/java-17-whats-new-openjdks-container-awareness"&gt;Java 17: What’s new in OpenJDK's container awareness&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/20/create-and-manage-local-persistent-volumes-codeready-containers"&gt;Create and manage local persistent volumes with CodeReady Containers&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible"&gt;Deploy Keycloak single sign-on with Ansible&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/21/bind-kafka-cluster-nodejs-application-easy-way"&gt;Bind a Kafka cluster to a Node.js application the easy way&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/11/new-c-features-gcc-12"&gt;New C++ features in GCC 12&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/26/red-hat-developer-roundup-best-april-2022" title="Red Hat Developer roundup: Best of April 2022"&gt;Red Hat Developer roundup: Best of April 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Red Hat Developer Editorial Team</dc:creator><dc:date>2022-04-26T07:00:00Z</dc:date></entry><entry><title type="html">Extending your configuration with YAML</title><link rel="alternate" href="https://wildfly.org//news/2022/04/26/YAML-configuration-extension/" /><author><name>Emmanuel Hugonnet</name></author><id>https://wildfly.org//news/2022/04/26/YAML-configuration-extension/</id><updated>2022-04-26T05:00:00Z</updated><content type="html">In WildFly the configuration is managed and stored in the standalone.xml. You have several ways to customize your configuration: edit the XML manually (which is not the recommended approach) or create jboss-cli scripts that you can run on each upgrade. So why propose a 'new' solution to customize a server configuration ? Well the idea was to be able to externalize the customization from the 'standard' provided configuration to facilitate server upgrades: just unzip the new release, install/provision your applications and run the same command line. This can also be done with cli scripts that are executed on boot. But those are a bit tricky to write since you have no idempotence on each boot. That’s why we have introduced a new way to do this by using YAML configuration files. The server will be started in read-only mode, that means that you can’t update the configuration and expect your changes to be persisted. Warning Please note that this feature is considered EXPERIMENTAL and thus is DISABLED by default. ACTIVATING THE FEATURE To enable that feature you need to add a ServiceLoader configuration in the org.jboss.as.controller*_ module. You need to create the following file: META-INF/services/org.jboss.as.controller.persistence.ConfigurationExtension containing a single line org.jboss.as.controller.persistence.yaml.YamlConfigurationExtension in the dir folder of the org.jboss.as.controller module. mkdir -p $WILDFLY_HOME/modules/system/layers/base/org/jboss/as/controller/main/dir/META-INF/services/ echo 'org.jboss.as.controller.persistence.yaml.YamlConfigurationExtension' &gt; $WILDFLY_HOME/modules/system/layers/base/org/jboss/as/controller/main/dir/META-INF/services/org.jboss.as.controller.persistence.ConfigurationExtension WRITTING THE YAML Warning Note that the YAML structure doesn’t follow the XML model but . The goal of the YAML files is to be able to customize an existing configuration. It is not here to replace the existing configuration support with XML. As such we won’t support part of the management model. Only those elements would be supported: * core-service * interface * socket-binding-group * subsystem * system-property That means that at least those entries would be ignored: * extension: to add extension to the server as this might require modules which can be missing. * deployment: to add deployments to the server as this require more that just some configuration. * deployment-overlay: to add deployment-overlays to the server as this require more that just some configuration. * path: since those should already have been defined when the YAML files are parsed. The YAML root node must be wildfly-configuration, then you can follow the model tree to add, remove or update resources. If a resource is already present (created by the XML or a previous YAML file) then we will update it, otherwise we will create it. Sample YAML file to define a new PostGresql datasource: wildfly-configuration: subsystem: datasources: jdbc-driver: postgresql: driver-name: postgresql driver-xa-datasource-class-name: org.postgresql.xa.PGXADataSource driver-module-name: org.postgresql.jdbc data-source: PostgreSQLDS: enabled: true exception-sorter-class-name: org.jboss.jca.adapters.jdbc.extensions.postgres.PostgreSQLExceptionSorter jndi-name: java:jboss/datasources/PostgreSQLDS jta: true max-pool-size: 20 min-pool-size: 0 connection-url: "jdbc:postgresql://localhost:5432}/demo" driver-name: postgresql user-name: postgres password: postgres validate-on-match: true background-validation: false background-validation-millis: 10000 flush-strategy: FailingConnectionOnly statistics-enable: false stale-connection-checker-class-name: org.jboss.jca.adapters.jdbc.extensions.novendor.NullStaleConnectionChecker valid-connection-checker-class-name: org.jboss.jca.adapters.jdbc.extensions.postgres.PostgreSQLValidConnectionChecker transaction-isolation: TRANSACTION_READ_COMMITTED As you can see, we are defining a jdbc-driver called postgresql and a data-source called PostgreSQLDS. Note Note that binaries is not managed by the YAML file, you need to create or provision the org.postgresql.jdbc module. OPERATIONS We also provide three operations using tags to provide more flexibility in what you can do with the YAML file. !UNDEFINE: TO UNDEFINE AN ATTRIBUTE Sample YAML file to undefine the CONSOLE logger level: wildfly-configuration: subsystem: logging: console-handler: CONSOLE: level: !undefine !REMOVE: TO REMOVE THE RESOURCE Sample YAML file to remove the embedded Artemis broker and connect to a remote broker: wildfly-configuration: socket-binding-group: standard-sockets: remote-destination-outbound-socket-binding: remote-artemis: host: localhost port: 61616 subsystem: messaging-activemq: server: default: !remove remote-connector: artemis: socket-binding: remote-artemis pooled-connection-factory: RemoteConnectionFactory: connectors: - artemis entries: - "java:jboss/RemoteConnectionFactory" - "java:jboss/exported/jms/RemoteConnectionFactory" enable-amq1-prefix: false user: admin password: admin ejb3: default-resource-adapter-name: RemoteConnectionFactory ee: service: default-bindings: jms-connection-factory: "java:jboss/RemoteConnectionFactory" !LIST-ADD: TO ADD AN ELEMENT TO A LIST (WITH AN OPTIONNAL INDEX). Sample YAML file to add a RemoteTransactionPermission to the permissions list at the position 0: wildfly-configuration: subsystem: elytron: permission-set: default-permissions: permissions: !list-add - class-name: org.wildfly.transaction.client.RemoteTransactionPermission module: org.wildfly.transaction.client target-name: "*" index: 0 As you may have noticed the index attribute doesn’t exist. It is used to know where to place the entry. If none is defined then the entry will be appended to the list. STARTING WITH YAML FILES Using the --yaml or -y argument you can pass a list of YAML files. Each path needs to be separated by the File.pathSeparator. It is a semicolon (;) on Windows and colon (:) on Mac and Unix-based operating systems. Paths can be absolute, relative to the current execution directory or relative to the standalone configuration directory. ./standalone.sh -y=/home/ehsavoie/dev/wildfly/config2.yml:config.yml -c standalone-full.xml YouTube video player</content><dc:creator>Emmanuel Hugonnet</dc:creator></entry><entry><title>Quarkus 2.8.2.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-8-2-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-8-2-final-released/</id><updated>2022-04-26T00:00:00Z</updated><published>2022-04-26T00:00:00Z</published><summary type="html">Today, we released 2.8.2.Final which, as usual, only contains bugfixes and documentation improvements. It is a safe upgrade for anyone already using 2.8. If you are not using 2.8 already, please refer to the 2.8 migration guide. Full changelog You can get the full changelog of 2.8.2.Final on GitHub. Come...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2022-04-26T00:00:00Z</dc:date></entry><entry><title>New C++ features in GCC 12</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/25/new-c-features-gcc-12" /><author><name>Marek Polacek</name></author><id>7bf98d00-e2bb-4cf0-922e-dddc68d2807b</id><updated>2022-04-25T07:00:00Z</updated><published>2022-04-25T07:00:00Z</published><summary type="html">&lt;p&gt;Version 12.1 of the &lt;a href="https://gcc.gnu.org/"&gt;GNU Compiler Collection&lt;/a&gt; (GCC) is expected to be released in April 2022. Like every major GCC release, this version will bring many &lt;a href="https://gcc.gnu.org/gcc-12/changes.html"&gt;additions, improvements, bug fixes, and new features&lt;/a&gt;. GCC 12 is already the system compiler in &lt;a href="https://fedoraproject.org/wiki/Changes/GNUToolchainF36"&gt;Fedora 36&lt;/a&gt;. GCC 12 will also be available on &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; in the Red Hat Developer Toolset (version 7) or the Red Hat GCC Toolset (version 8 and 9).&lt;/p&gt; &lt;p&gt;Like the article I wrote about &lt;a href="https://developers.redhat.com/blog/2020/09/24/new-c-features-in-gcc-10"&gt;GCC 10&lt;/a&gt;, this article describes only new features affecting C++.&lt;/p&gt; &lt;p&gt;We implemented several C++23 proposals in GCC 12. The default dialect in GCC 12 is &lt;code&gt;-std=gnu++17&lt;/code&gt;; to enable C++23 features, use the &lt;code&gt;-std=c++23&lt;/code&gt; or &lt;code&gt;-std=gnu++23&lt;/code&gt; command-line options. (The latter option allows GNU extensions.)&lt;/p&gt; &lt;p&gt;Note that C++20 and C++23 features are still experimental in GCC 12.&lt;/p&gt; &lt;h2&gt;C++23 features&lt;/h2&gt; &lt;p&gt;A number of previously prohibited constructs are now allowed, and some of these features can potentially reduce the size of your programs.&lt;/p&gt; &lt;h3&gt;if consteval&lt;/h3&gt; &lt;p&gt;C++17 introduced the &lt;em&gt;constexpr if&lt;/em&gt; statement. The condition in &lt;code&gt;if constexpr&lt;/code&gt; must be a constant expression (it is &lt;em&gt;manifestly constant evaluated&lt;/em&gt;). If the condition evaluates to true, the &lt;code&gt;else&lt;/code&gt; branch, if present, is &lt;em&gt;discarded.&lt;/em&gt; Discarded means that the &lt;code&gt;else&lt;/code&gt; branch is not instantiated at all during compilation, which is different behavior from an ordinary &lt;code&gt;if&lt;/code&gt;. If the condition evaluates to false, the &lt;code&gt;then&lt;/code&gt; branch is similarly discarded.&lt;/p&gt; &lt;p&gt;If a function is declared &lt;code&gt;constexpr&lt;/code&gt;, it might or might not be evaluated at compile time, depending on the context. To offer some visibility to the programmer about when the function is evaluated at compile time, C++20 introduced a new library function, &lt;code&gt;std::is_constant_evaluated&lt;/code&gt;, which returns true if the current context is evaluated at compile time:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#include &lt;type_traits&gt; int slow (int); constexpr int fn (int n) { if (std::is_constant_evaluated ()) return n &lt;&lt; 1; // #1 else return slow (n); // #2 } constexpr int i = fn (10); // does #1 int n = 10; int i2 = fn (n); // calls slow function #2 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;C++20 introduced the &lt;code&gt;consteval&lt;/code&gt; keyword. A (possibly member) function or a constructor marked as &lt;code&gt;consteval&lt;/code&gt; is an &lt;em&gt;immediate function&lt;/em&gt;. Immediate functions are evaluated during compilation and must produce a constant, unless the call to an immediate function takes place in another immediate function; if they don't, the compiler produces an error. The compiler doesn't emit any actual code for such functions.&lt;/p&gt; &lt;p&gt;However, the language rules do not allow the developer to replace &lt;code&gt;n &lt;&lt; 1&lt;/code&gt; in the preceding test with a call to a &lt;code&gt;consteval&lt;/code&gt; function:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#include &lt;type_traits&gt; int slow (int); consteval int fast (int n) { return n &lt;&lt; 1; } constexpr int fn (int n) { if (std::is_constant_evaluated ()) return fast (n); // 'n' is not a constant expression else return slow (n); } constexpr int i = fn (10); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To fix this problem, &lt;a href="https://wg21.link/p1938"&gt;proposal P1938R3&lt;/a&gt; introduced &lt;code&gt;if consteval&lt;/code&gt;, which GCC 12 implements. &lt;code&gt;if consteval&lt;/code&gt; allows the developer to invoke immediate functions, as shown here:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#include &lt;type_traits&gt; int slow (int); consteval int fast (int n) { return n &lt;&lt; 1; } constexpr int fn (int n) { if consteval { return fast (n); // OK } else { return slow (n); } } constexpr int i = fn (10); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that it is valid to have &lt;code&gt;if consteval&lt;/code&gt; in an ordinary, non-&lt;code&gt;constexpr&lt;/code&gt; function. Also note that &lt;code&gt;if consteval&lt;/code&gt; requires &lt;code&gt;{ }&lt;/code&gt;, unlike the ordinary &lt;code&gt;if&lt;/code&gt; statement.&lt;/p&gt; &lt;p&gt;There is a problem with the interaction between &lt;code&gt;if constexpr&lt;/code&gt; and &lt;code&gt;std::is_constant_evaluated&lt;/code&gt;, but fortunately the compiler can detect that problem. We'll examine the solution in the later section &lt;em&gt;Extended std::is_constant_evaluated in if warning&lt;/em&gt;.&lt;/p&gt; &lt;h3&gt;auto(x)&lt;/h3&gt; &lt;p&gt;GCC 12 implements &lt;a href="https://wg21.link/p0849"&gt;proposal P0849&lt;/a&gt;, which allows &lt;code&gt;auto&lt;/code&gt; in a &lt;em&gt;function-style cast&lt;/em&gt;, the result of which is a &lt;a href="https://en.cppreference.com/w/cpp/language/value_category"&gt;pure rvalue (&lt;em&gt;prvalue&lt;/em&gt;)&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;struct A {}; void f(A&amp;); // #1 void f(A&amp;&amp;); // #2 A&amp; g(); void h() { f(g()); // calls #1 f(auto(g())); // calls #2 with a temporary object } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that both &lt;code&gt;auto(x)&lt;/code&gt; and &lt;code&gt;auto{x}&lt;/code&gt; are accepted; however, &lt;code&gt;decltype(auto)(x)&lt;/code&gt; remains invalid.&lt;/p&gt; &lt;h3&gt;Non-literal variables in constexpr functions&lt;/h3&gt; &lt;p&gt;GCC 12 implements &lt;a href="https://wg21.link/p2242"&gt;C++23 proposal P2242R3&lt;/a&gt;, which allows non-literal variables, gotos, and labels in &lt;code&gt;constexpr&lt;/code&gt; functions so long as they are not constant evaluated. This expanded behavior is useful for code like the following (taken from the proposal):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#include &lt;type_traits&gt; template&lt;typename T&gt; constexpr bool f() { if (std::is_constant_evaluated()) { return true; } else { T t; // OK when T=nonliteral in C++23 return true; } } struct nonliteral { nonliteral(); }; static_assert(f&lt;nonliteral&gt;()); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This does not compile in C++20, but compiles in C++23 because the &lt;code&gt;else&lt;/code&gt; branch is not evaluated. The following example also compiles only in C++23:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;constexpr int foo (int i) { if (i == 0) return 42; static int a; thread_local int t; goto label; label: return 0; } &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Multidimensional subscript operator&lt;/h3&gt; &lt;p&gt;GCC 12 supports C++23 &lt;a href="https://wg21.link/p2128"&gt;proposal P2128R6&lt;/a&gt;, a multidimensional subscript operator. Comma expressions within subscripting expressions were deprecated in C++20 via &lt;a href="https://wg21.link/p1161"&gt;proposal P1161R3&lt;/a&gt;, and in C++23 the comma in &lt;code&gt;[ ]&lt;/code&gt; has changed meaning.&lt;/p&gt; &lt;p&gt;C++ uses the &lt;code&gt;operator[]&lt;/code&gt; member function to access the elements of an array, as well as array-like types such as &lt;code&gt;std::array&lt;/code&gt;, &lt;code&gt;std::span&lt;/code&gt;, &lt;code&gt;std::vector&lt;/code&gt;, and &lt;code&gt;std::string&lt;/code&gt;. However, this operator did not accept multiple arguments in C++20, so access to the elements of multidimensional arrays was implemented using function call operators like &lt;code&gt;arr(x, y, z)&lt;/code&gt;, and similar workarounds. These workarounds have a number of drawbacks, so to alleviate the issues when using them, C++23 allows &lt;code&gt;operator[]&lt;/code&gt; to take zero or more arguments.&lt;/p&gt; &lt;p&gt;As a consequence, this test case is accepted with &lt;code&gt;-std=c++23&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;template &lt;typename... T&gt; struct W { constexpr auto operator[](T&amp;&amp;...); }; W&lt;&gt; w1; W&lt;int&gt; w2; W&lt;int, int&gt; w3; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here is what may be a clearer example, with a very naive implementation:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;struct S { int a[64]; constexpr S () : a {} {}; constexpr S (int x, int y, int z) : a {x, y, z} {}; constexpr int &amp;operator[] () { return a[0]; } constexpr int &amp;operator[] (int x) { return a[x]; } constexpr int &amp;operator[] (int x, long y) { return a[x + y * 8]; } }; void g () { S s; s[] = 42; s[5] = 36; s[3, 4] = 72; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As an extension, GCC still supports the old behavior when an overloaded subscript operator is not found, though it issues a warning:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;void f(int a[], int b, int c) { a[b,c]; // deprecated in C++20, invalid but accepted with a warning in C++23 a[(b,c)]; // OK in both C++20 and C++23 } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that currently, &lt;code&gt;operator[]&lt;/code&gt; does not support default arguments. It appears, though, that default arguments will be allowed in future versions: see &lt;a href="https://wg21.link/cwg2507"&gt;CWG 2507&lt;/a&gt;. If and when the proposed adjustment is accepted, the following example will be allowed:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;struct X { int a[64]; constexpr int&amp; operator[](int i = 1) { return a[i]; } }; &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;elifdef and elifndef&lt;/h3&gt; &lt;p&gt;In C and C++, the &lt;code&gt;#ifdef&lt;/code&gt; and &lt;code&gt;#ifndef&lt;/code&gt; preprocessing directives are "syntactic sugar" for &lt;code&gt;#if defined(something)&lt;/code&gt; and &lt;code&gt;#if !defined(something)&lt;/code&gt;. Surprisingly, the &lt;code&gt;else&lt;/code&gt; variants of these directives did not have the same shorthands. To amend this omission, the C and C++ designers accepted proposals &lt;a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2645.pdf"&gt;N2645&lt;/a&gt; and &lt;a href="https://wg21.link/p2334"&gt;P2334R1&lt;/a&gt;, respectively. GCC 12 implements both proposals, so the following example compiles correctly:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#ifdef __STDC__ /* ... */ #elifndef __cplusplus #warning "not ISO C" #else /* ... */ #endif &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Please note that, to compile this example without errors in C++20 and earlier, you must enable GNU extensions. In other words, &lt;code&gt;-std=c++20&lt;/code&gt; causes a compile error, but &lt;code&gt;-std=gnu++20&lt;/code&gt; causes only a pedantic warning if &lt;code&gt;-Wpedantic&lt;/code&gt; is also turned on.&lt;/p&gt; &lt;h3&gt;Extended init-statement&lt;/h3&gt; &lt;p&gt;GCC 12 implements &lt;a href="https://wg21.link/p2360r0"&gt;proposal P2360R0&lt;/a&gt; in C++23, which merely extends an &lt;em&gt;init-statement&lt;/em&gt; (used in &lt;code&gt;if&lt;/code&gt;, &lt;code&gt;for&lt;/code&gt;, and &lt;code&gt;switch&lt;/code&gt; statements) to allow it to contain an &lt;em&gt;alias-declaration&lt;/em&gt;. In practice, that change means that the following code is accepted:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;for (using T = int; T e : v) { // use e } &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Corrections and internal improvements&lt;/h2&gt; &lt;p&gt;The changes described in this section bring GCC more in line with recent changes to the standard, and permit behavior that previously did not work correctly.&lt;/p&gt; &lt;h3&gt;Dependent operator lookup changes&lt;/h3&gt; &lt;p&gt;GCC 12 corrected a problem where the compiler performed an unqualified lookup for a dependent operator expression at template definition time instead of at instantiation time. The fix matches the existing behavior for dependent call expressions. Consider the following test case demonstrating this change:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#include &lt;iostream&gt; namespace N { struct A { }; } void operator+(N::A, double) { std::cout &lt;&lt; "#1 "; } template&lt;class T&gt; void f(T t) { operator+(t, 0); t + 0; } // Since it's not visible from the template definition, this later-declared // operator overload should not be considered when instantiating f&lt;N::A&gt;(N::A), // for either the call or operator expression. void operator+(N::A, int) { std::cout &lt;&lt; "#2 "; } int main() { N::A a; f(a); std::cout &lt;&lt; std::endl; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This program will print &lt;code&gt;#1 #2&lt;/code&gt; when compiled with versions 11 or older of GCC, but GCC 12 correctly prints &lt;code&gt;#1 #1&lt;/code&gt;. That's because previously only the call expression resolved to the &lt;code&gt;#1&lt;/code&gt; overload, but with GCC 12 the operator expression does too.&lt;/p&gt; &lt;h3&gt;auto specifier for pointers and references to arrays&lt;/h3&gt; &lt;p&gt;GCC 12 also supports &lt;a href="https://wg21.link/cwg2397"&gt;defect report DR2397&lt;/a&gt;, covering the &lt;code&gt;auto&lt;/code&gt; specifier for pointers and references to arrays. This change removes the restriction that the array element type may not be a &lt;em&gt;placeholder type&lt;/em&gt;. This allows code like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;int a[3]; auto (*p)[3] = &amp;a; auto (&amp;r)[3] = a; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, neither of the following examples work (although some day they might):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;auto (&amp;&amp;r)[2] = { 1, 2 }; auto arr[2] = { 1, 2 }; int arr[5]; auto x[5] = arr; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;These don't work because the &lt;code&gt;auto&lt;/code&gt; deduction is performed in terms of function template argument deduction, so the array decays to a pointer.&lt;/p&gt; &lt;h3&gt;Folding of trivial functions&lt;/h3&gt; &lt;p&gt;A well-formed call to &lt;code&gt;std::move&lt;/code&gt; or &lt;code&gt;std::forward&lt;/code&gt; is equivalent to a cast. But because these constructs are implemented as function calls, the compiler generates debugging information that persists even after the call gets inlined. This extra code is a waste because there's no need to debug such operations. Therefore, GCC 12 elides calls to certain trivial inline functions (such as &lt;code&gt;std::move&lt;/code&gt;, &lt;code&gt;std::forward&lt;/code&gt;, &lt;code&gt;std::addressof&lt;/code&gt;, and &lt;code&gt;std::as_const&lt;/code&gt;) into simple casts as part of the front end's general expression folding routine. As a result, the debugging information produced by GCC could be up to 10 percent smaller, while improving GCC's compile time and memory usage. This behavior is controlled by a new option called &lt;code&gt;-ffold-simple-inlines&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Fixing the overly permissive specification of enum direct-list-initialization&lt;/h3&gt; &lt;p&gt;GCC 12 implements &lt;a href="https://wg21.link/cwg2374"&gt;defect report DR2374&lt;/a&gt;, which forbids, for instance, &lt;em&gt;direct-list-initialization&lt;/em&gt; of a scoped enumeration from a different scoped enumeration:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;enum class Orange; enum class Apple; Orange o; Apple a{o}; // error with GCC 12 &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Restrictions on non-type template arguments in partial specializations&lt;/h3&gt; &lt;p&gt;Previously, an overly strict restriction prevented certain uses of template parameters as template arguments. This restriction has been rectified in response to &lt;a href="http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1315"&gt;defect report DR1315&lt;/a&gt;, and GCC implements these uses now. Therefore, the following plausible use of a template parameter as a template argument compiles correctly:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;template &lt;int I, int J&gt; struct A {}; template &lt;int I&gt; struct A&lt;I, I*2&gt; {}; // OK with GCC 12 &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Substitutions into function parameters in lexical order&lt;/h3&gt; &lt;p&gt;C++ template argument deduction underwent some changes when &lt;a href="http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1227"&gt;defect report DR1227&lt;/a&gt; specified that the substitution proceeds in lexical order—that is, from left to right. The following code demonstrates what effect this might have:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;template &lt;typename T&gt; struct A { using type = typename T::type; }; template &lt;typename T&gt; void g(T, typename A&lt;T&gt;::type); template &lt;typename T&gt; long g(...); long y = g&lt;void&gt;(0, 0); // OK in GCC 12, error in GCC 11 template &lt;class T&gt; void h(typename A&lt;T&gt;::type, T); template &lt;class T&gt; long h(...); long z = h&lt;void&gt;(0, 0); // error in GCC 12, OK in GCC 11 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;GCC 12 substitutes the arguments in left-to-right order and checks whether a substituted type is erroneous before substituting it into the rest of the arguments. Thus, for &lt;code&gt;g&lt;void&gt;(0, 0)&lt;/code&gt; the compiler tries to substitute &lt;code&gt;void&lt;/code&gt; into &lt;code&gt;g(T, typename A&lt;T&gt;::type)&lt;/code&gt; and sees that the first substitution results in an invalid parameter type &lt;code&gt;void&lt;/code&gt;. This invalid substitution is a SFINAE failure, so the first overload is discarded and the &lt;code&gt;g(...)&lt;/code&gt; one is chosen instead. However, for &lt;code&gt;h&lt;void&gt;(0, 0)&lt;/code&gt;, the compiler first substitutes &lt;code&gt;void&lt;/code&gt; into the &lt;code&gt;typename A&lt;T&gt;::type&lt;/code&gt; parameter. This produces a hard error, because instantiating &lt;code&gt;A&lt;void&gt;&lt;/code&gt; is not an immediate context.&lt;/p&gt; &lt;p&gt;GCC 11 and earlier performed the substitution in right-to-left order, so the situation was reversed: &lt;code&gt;g&lt;void&gt;(0, 0)&lt;/code&gt; resulted in a compile error, whereas &lt;code&gt;h&lt;void&gt;(0, 0)&lt;/code&gt; compiled fine.&lt;/p&gt; &lt;h3&gt;Stricter checking of attributes on friend declarations&lt;/h3&gt; &lt;p&gt;If a friend declaration has an attribute, that declaration must be a definition, but before version 12, GCC didn't check this restriction. Moreover, a C++11 attribute cannot appear in the middle of the &lt;em&gt;decl-specifier-seq&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;template&lt;typename T&gt; struct S { [[deprecated]] friend T; // warning: attribute ignored [[deprecated]] friend void f(); // warning: attribute ignored friend [[deprecated]] int f2(); // error }; S&lt;int&gt; s; &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Deduction guides can be declared at class scope&lt;/h3&gt; &lt;p&gt;Due to a bug, deduction guides could not be declared at class scope in versions 11 and early of GCC. This has been &lt;a href="https://gcc.gnu.org/PR79501"&gt;fixed in GCC 12&lt;/a&gt;, so the following test case compiles correctly:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;struct X { template&lt;typename T&gt; struct A {}; A() -&gt; A&lt;int&gt;; }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Class-scope non-template deduction guides are now supported as well in GCC 12.&lt;/p&gt; &lt;h3&gt;Ordered comparison of null pointers is now rejected&lt;/h3&gt; &lt;p&gt;Relational comparisons between null pointer constants and pointers are ill-formed, and this error is diagnosed in GCC 12:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;decltype(nullptr) foo (); auto cmp = foo () &gt; 0; // error: ordered comparison of pointer with integer zero &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The overall defect resolution status is listed in the &lt;a href="https://gcc.gnu.org/projects/cxx-dr-status.html"&gt;C++ Defect Report Support in GCC&lt;/a&gt; page.&lt;/p&gt; &lt;h2&gt;New and improved warnings&lt;/h2&gt; &lt;p&gt;GCC's plethora of warning options have been enhanced in GCC 12.&lt;/p&gt; &lt;h3&gt;-Wuninitialized extended&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;-Wuninitialized&lt;/code&gt; warning has been extended to warn about using uninitialized variables in member initializer lists. Therefore, the front end can detect bugs like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;struct A { int a; int b; A() : b(1), a(b) { } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here, the &lt;code&gt;b&lt;/code&gt; field is used uninitialized because the order of member initializers in the member initializer list is irrelevant; what matters is the order of declarations in the class definition. (A related warning, &lt;code&gt;-Wreorder&lt;/code&gt;, can be used to warn when the order of member initializers does not match the declaration order.)&lt;/p&gt; &lt;p&gt;The warning does not warn about more complex initializers. And it also does not warn when the address of an object is used:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;struct B { int &amp;r; int *p; int a; B() : r(a), p(&amp;a), a(1) { } // no warning }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As an aside, the request to enhance this warning came about 17 years ago. Apparently, sometimes things take time.&lt;/p&gt; &lt;h3&gt;-Wbidi-chars added&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;-Wbidi-chars&lt;/code&gt; warning warns about potentially misleading UTF-8 bidirectional control characters, which can change left-to-right writing direction into right-to-left (and vice versa). Certain combinations of control characters might cause confusion for the programmer because code that has seemingly been commented out might actually be compiled, or vice versa. This warning is supposed to mitigate &lt;a href="https://nvd.nist.gov/vuln/detail/CVE-2021-42574"&gt;CVE-2021-42574&lt;/a&gt;, aka &lt;a href="https://trojansource.codes/"&gt;Trojan Source&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For more information, please refer to David Malcolm's Red Hat Developer article &lt;a href="https://developers.redhat.com/articles/2022/01/12/prevent-trojan-source-attacks-gcc-12"&gt;Prevent Trojan Source attacks with GCC 12&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;-Warray-compare added&lt;/h3&gt; &lt;p&gt;The new &lt;code&gt;-Warray-compare&lt;/code&gt; option warns about comparisons between two operands of array type, which was deprecated in C++20. Here's an example of this situation:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;int arr1[5]; int arr2[5]; bool same = arr1 == arr2; // warning: comparison between two arrays &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;-Wattributes extended&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;-Wattributes&lt;/code&gt; warning has been extended so that developers can now use &lt;code&gt;-Wno-attributes=ns::attr&lt;/code&gt; or &lt;code&gt;-Wno-attributes=ns::&lt;/code&gt; to suppress warnings about unknown scoped attributes (in C++11 and C2X). Similarly, &lt;code&gt;#pragma GCC diagnostic ignored_attributes "ns::attr"&lt;/code&gt; can be used to achieve the same effect. The new behavior is meant to help with vendor-specific attributes, where a warning is not desirable, while still detecting typos. Consider:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;[[deprecate]] void g(); // warning: should be deprecated [[company::attr]] void f(); // no warning &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When compiled with &lt;code&gt;-Wno-attributes=company::&lt;/code&gt;, only the first declaration issues a warning.&lt;/p&gt; &lt;h3&gt;New warning options for C++ language mismatches&lt;/h3&gt; &lt;p&gt;GCC 12 gained the following new warning options, enabled by default:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wc++11-extensions&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wc++14-extensions&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wc++17-extensions&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wc++20-extensions&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wc++23-extensions&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These options control existing pedantic warnings about occurrences of new C++ constructs in code that uses an older C++ standard dialect. For instance, developers are now able to suppress warnings when using variadic templates in C++98 code by applying the new &lt;code&gt;-Wno-c++11-extensions&lt;/code&gt; option.&lt;/p&gt; &lt;h3&gt;Extended std::is_constant_evaluated in if warning&lt;/h3&gt; &lt;p&gt;Because the condition in &lt;code&gt;if constexpr&lt;/code&gt; is &lt;em&gt;manifestly constant evaluated&lt;/em&gt;, &lt;code&gt;if constexpr (std::is_constant_evaluated())&lt;/code&gt; is always evaluated to be true. GCC 10 introduced a warning to detect this bug, and GCC 12 extended the warning to detect more dubious cases. For instance:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#include &lt;type_traits&gt; int foo () { if (std::is_constant_evaluated ()) // warning: always evaluates to false in a non-constexpr function return 1; return 0; } consteval int baz () { if (std::is_constant_evaluated ()) // warning: always evaluates to true in a consteval function return 1; return 0; } &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;-Wmissing-requires added&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;-Wmissing-requires&lt;/code&gt; option warns about a missing &lt;code&gt;requires&lt;/code&gt;. Consider the following code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;template &lt;typename T&gt; concept Foo = __is_same(T, int); template&lt;typename Seq&gt; concept Sequence = requires (Seq s) { /* requires */ Foo&lt;Seq&gt;; }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The problem here is that the developer presumably meant to invoke the &lt;code&gt;Foo&lt;/code&gt; concept (a nested requirement), which needs to be prefixed by the &lt;code&gt;requires&lt;/code&gt; keyword. In this test, &lt;code&gt;Foo&lt;Seq&gt;&lt;/code&gt; is a &lt;em&gt;concept-id&lt;/em&gt;, which makes &lt;code&gt;Sequence&lt;/code&gt; true if &lt;code&gt;Foo&lt;Seq&gt;&lt;/code&gt; is a valid expression. The expression is valid for all &lt;code&gt;Seq&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;-Waddress enhanced&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;-Waddress&lt;/code&gt; warning has been extended. It now warns about, for instance, comparing the address of a nonstatic member function to the null pointer value:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;struct S { void f(); }; int g() { if (&amp;S::f == nullptr) // warning: the address &amp;S::f will never be NULL return -1; return 0; } &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;As usual, I'd like to thank my coworkers at Red Hat who made the GNU C++ compiler so much better, notably Jason Merrill, Jakub Jelinek, Patrick Palka, and Jonathan Wakely.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In GCC 13, we plan to finish up the remaining C++23 features. For progress so far, see the &lt;a href="https://gcc.gnu.org/projects/cxx-status.html#cxx23"&gt;C++23 Language Features&lt;/a&gt; table on the &lt;a href="https://gcc.gnu.org/projects/cxx-status.html"&gt;C++ Standards Support in GCC&lt;/a&gt; page. Please do not hesitate to &lt;a href="https://gcc.gnu.org/bugs/"&gt;file bug reports&lt;/a&gt; in the meantime, and help us make GCC even better.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/25/new-c-features-gcc-12" title="New C++ features in GCC 12"&gt;New C++ features in GCC 12&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Marek Polacek</dc:creator><dc:date>2022-04-25T07:00:00Z</dc:date></entry></feed>
